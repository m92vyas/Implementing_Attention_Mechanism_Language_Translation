{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "nKBx5LFGnXHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ej64XodTO85"
      },
      "outputs": [],
      "source": [
        "# downloading data\n",
        "!wget http://www.manythings.org/anki/ita-eng.zip\n",
        "!unzip ita-eng.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processing Data**"
      ],
      "metadata": {
        "id": "idCMIoXenlLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading data\n",
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    print(f.readlines(500))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBxjssuAuxoO",
        "outputId": "fb3081cc-504f-47e7-f66a-74d1da3151e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hi.\\tCiao!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #607364 (Cero)\\n', 'Hi.\\tCiao.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4522287 (Guybrush88)\\n', 'Run!\\tCorri!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906347 (Guybrush88)\\n', 'Run!\\tCorra!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906348 (Guybrush88)\\n', 'Run!\\tCorrete!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906350 (Guybrush88)\\n', 'Who?\\tChi?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #2126402 (Guybrush88)\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataframe with english , italian sentences\n",
        "with open('ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "      a = i.split(\"\\t\")\n",
        "      eng.append(a[0])\n",
        "      ita.append(a[1])\n",
        "data = pd.DataFrame()\n",
        "data['english'] = eng\n",
        "data['italian'] = ita\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "u28_4fTXvbJw",
        "outputId": "adabd71a-972d-413f-812f-a434c65cfc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  english  \\\n",
              "0                                                     Hi.   \n",
              "1                                                     Hi.   \n",
              "2                                                    Run!   \n",
              "3                                                    Run!   \n",
              "4                                                    Run!   \n",
              "...                                                   ...   \n",
              "362856  I know that adding sentences only in your nati...   \n",
              "362857  I know that adding sentences only in your nati...   \n",
              "362858  I know that adding sentences only in your nati...   \n",
              "362859  Doubtless there exists in this world precisely...   \n",
              "362860  Doubtless there exists in this world precisely...   \n",
              "\n",
              "                                                  italian  \n",
              "0                                                   Ciao!  \n",
              "1                                                   Ciao.  \n",
              "2                                                  Corri!  \n",
              "3                                                  Corra!  \n",
              "4                                                Correte!  \n",
              "...                                                   ...  \n",
              "362856  So che aggiungere frasi soltanto nella sua lin...  \n",
              "362857  So che aggiungere frasi solamente nella sua li...  \n",
              "362858  So che aggiungere frasi solamente nella sua li...  \n",
              "362859  Senza dubbio esiste in questo mondo proprio la...  \n",
              "362860  Senza dubbio esiste in questo mondo proprio la...  \n",
              "\n",
              "[362861 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a87f3148-a911-4be2-80d5-542b2dca9fc8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362856</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi soltanto nella sua lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362857</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362858</th>\n",
              "      <td>I know that adding sentences only in your nati...</td>\n",
              "      <td>So che aggiungere frasi solamente nella sua li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362859</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362860</th>\n",
              "      <td>Doubtless there exists in this world precisely...</td>\n",
              "      <td>Senza dubbio esiste in questo mondo proprio la...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>362861 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a87f3148-a911-4be2-80d5-542b2dca9fc8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a87f3148-a911-4be2-80d5-542b2dca9fc8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a87f3148-a911-4be2-80d5-542b2dca9fc8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnDyE0ljbYor"
      },
      "outputs": [],
      "source": [
        "def decontractions(phrase): #https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    return phrase"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_eng(text):\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "7ro9frBoxUZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_ita(text):\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"'.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    text = text.lower()\n",
        "    return text"
      ],
      "metadata": {
        "id": "QU027YfrxVN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['english'] = data['english'].apply(preprocess_eng)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aDwh-dptxZAb",
        "outputId": "71376d55-eec1-4cb1-deea-1dde8d23213a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1      hi     ciao\n",
              "2     run    corri\n",
              "3     run    corra\n",
              "4     run  correte"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c69f66d-7c51-44de-8c30-616ebb7d7f09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c69f66d-7c51-44de-8c30-616ebb7d7f09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6c69f66d-7c51-44de-8c30-616ebb7d7f09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6c69f66d-7c51-44de-8c30-616ebb7d7f09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting length of sentences to select max_length\n",
        "def length_text(data):\n",
        "  len_data = []\n",
        "  for i in data:\n",
        "    len_data.append(len(i.split()))\n",
        "  return len_data"
      ],
      "metadata": {
        "id": "v6fTplFoy_Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ita_lengths = length_text(data['italian'].values)\n",
        "eng_lengths = length_text(data['english'].values)"
      ],
      "metadata": {
        "id": "IRFw5JSbzV7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.quantile(ita_lengths , [0,0.25,0.5,0.75,0.9,0.95,0.99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fm9tekaxzhPO",
        "outputId": "7c6061f1-9799-4684-8064-b321b6580ab5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  4.,  5.,  7.,  8.,  9., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.quantile(eng_lengths , [0,0.25,0.5,0.75,0.9,0.95,0.99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi4hK0Vp0KdG",
        "outputId": "aa932b56-5979-4298-b57a-a47b558d1467"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.,  4.,  6.,  7.,  8.,  9., 12.])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.quantile(ita_lengths , np.arange(.99,1,0.001)) # getting percentile value between 0.99 to 1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQbR-wQ60ap8",
        "outputId": "95c91e31-be8b-4a63-fb28-c3833ed91fe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([12., 12., 12., 13., 13., 13., 14., 15., 16., 22., 92.])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.quantile(eng_lengths , np.arange(.99,1,0.001))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6acz0qOg0jtQ",
        "outputId": "b779d7e2-08cc-421f-f8d7-753f34e19586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 12.,  12.,  13.,  13.,  13.,  14.,  14.,  15.,  16.,  25., 101.])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IypVGvYKREOL",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "ita_lengths = data['italian'].str.split().apply(len)\n",
        "eng_lengths = data['english'].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frL1wvLwSz7_"
      },
      "outputs": [],
      "source": [
        "# selecting maximum input length of 20 words\n",
        "\n",
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 20]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 20]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str) # decoder input starts with <start> token\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'   # decoder output ends with <end> token\n",
        "\n",
        "data = data.drop(['english','italian_len','english_len'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.english_inp.values[15000])\n",
        "print(data.english_out.values[15000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX8QRj7zpj1p",
        "outputId": "75520544-4fc2-4772-8533-2ba05194f935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> let tom drive\n",
            "let tom drive <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "svobsg_yXbux",
        "outputId": "6171ca36-eff7-4df8-c4e7-1118b9d31391"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            italian                             english_inp  \\\n",
              "99788          tom sembra devastato            <start> tom looks devastated   \n",
              "59360    aggiungete una spiegazione              <start> add an explanation   \n",
              "250904  avevo tutto sotto controllo  <start> i had everything under control   \n",
              "12678                   fu lapidato                   <start> he was stoned   \n",
              "123290      io non ve lo posso dare        <start> i can not give it to you   \n",
              "\n",
              "                                 english_out  \n",
              "99788             tom looks devastated <end>  \n",
              "59360               add an explanation <end>  \n",
              "250904  i had everything under control <end>  \n",
              "12678                    he was stoned <end>  \n",
              "123290        i can not give it to you <end>  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b680214f-c05a-490e-86b8-5f9ea8d4c9fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>99788</th>\n",
              "      <td>tom sembra devastato</td>\n",
              "      <td>&lt;start&gt; tom looks devastated</td>\n",
              "      <td>tom looks devastated &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59360</th>\n",
              "      <td>aggiungete una spiegazione</td>\n",
              "      <td>&lt;start&gt; add an explanation</td>\n",
              "      <td>add an explanation &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250904</th>\n",
              "      <td>avevo tutto sotto controllo</td>\n",
              "      <td>&lt;start&gt; i had everything under control</td>\n",
              "      <td>i had everything under control &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12678</th>\n",
              "      <td>fu lapidato</td>\n",
              "      <td>&lt;start&gt; he was stoned</td>\n",
              "      <td>he was stoned &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123290</th>\n",
              "      <td>io non ve lo posso dare</td>\n",
              "      <td>&lt;start&gt; i can not give it to you</td>\n",
              "      <td>i can not give it to you &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b680214f-c05a-490e-86b8-5f9ea8d4c9fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b680214f-c05a-490e-86b8-5f9ea8d4c9fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b680214f-c05a-490e-86b8-5f9ea8d4c9fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG50P52vhMu8"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "trainval, test = train_test_split(data, test_size=0.003) # for test set getting appox. 1000 sentences\n",
        "train, val = train_test_split(trainval, test_size=0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mp9dzm1hwv-",
        "outputId": "3d442a19-5798-433c-a129-727cd15038b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(307077, 3) (54191, 3) (1088, 3)\n"
          ]
        }
      ],
      "source": [
        "print(train.shape, val.shape, test.shape)\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAMqqi8GaGvq"
      },
      "outputs": [],
      "source": [
        "# tokenizing\n",
        "\n",
        "tknizer_ita = Tokenizer()\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n') # filter same as default except < , >\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1AC6vShbsyf",
        "outputId": "092a746f-6c06-4260-b904-9c52890c3b22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13335\n",
            "27402\n"
          ]
        }
      ],
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poK5koaDb7KO",
        "outputId": "f556b762-07bd-48d6-ec7c-34979f4b14be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10668)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting glove vectors\n",
        "!wget https://www.dropbox.com/s/ddkmtqz01jc024u/glove.6B.100d.txt"
      ],
      "metadata": {
        "id": "r0gAaYHDniUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I8sqk4nefgN"
      },
      "outputs": [],
      "source": [
        "# embedding matrix using glove 100d embeddings\n",
        "\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\n",
        "for word, i in tknizer_eng.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BNmkA74APKU",
        "outputId": "149eeaa3-6b9e-41ed-f3f4-b22d9726819d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13336, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Loader:**"
      ],
      "metadata": {
        "id": "tJDATf05rIFX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mBXRd_sus3C"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]])  # tokenizing input italian sentence\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]]) # tokenizing decoder input \n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]]) # tokenizing decoder output\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        \n",
        "        return tuple([[batch[0],batch[1]],batch[2]]) #input to encoder:italian sent, input to decoder:eng sent with <start>, decoder output:eng sent with <end>\n",
        "\n",
        "    def __len__(self): \n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Model:**"
      ],
      "metadata": {
        "id": "LNhofLP204vr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![seq2seq_attention_mechanism_new.svg](data:image/svg+xml;base64,<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:lucid="lucid" width="1300" height="1034"><g transform="translate(0 -320)" lucid:page-tab-id="0_0"><path d="M1060.4 1080c0-11.05 8.95-20 20-20h14.4c11.05 0 20 8.95 20 20v234c0 11.05-8.95 20-20 20h-14.4c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-opacity="0" stroke-width=".5" fill="#d1bcd2" fill-opacity=".3"/><path d="M60 360c0-11.05 8.95-20 20-20h580c11.05 0 20 8.95 20 20v460c0 11.05-8.95 20-20 20H80c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-opacity="0" stroke-width=".5" fill="#f5b5c8" fill-opacity=".3"/><path d="M60 881c0-11.05 8.95-20 20-20h580c11.05 0 20 8.95 20 20v118c0 11.05-8.95 20-20 20H80c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-opacity="0" stroke-width=".5" fill="#d1bcd2" fill-opacity=".3"/><path d="M100 896c0-8.28 6.72-15 15-15h70c8.28 0 15 6.72 15 15v50c0 8.28-6.72 15-15 15h-70c-8.28 0-15-6.72-15-15z" stroke="#000" stroke-width="3" fill="#fff" fill-opacity=".48"/><use xlink:href="#a" transform="matrix(1,0,0,1,100,881.0000000000001) translate(17.994791666666664 47.994791666666664)"/><path d="M320 896c0-8.28 6.72-15 15-15h70c8.28 0 15 6.72 15 15v50c0 8.28-6.72 15-15 15h-70c-8.28 0-15-6.72-15-15z" stroke="#000" stroke-width="3" fill="#fff" fill-opacity=".48"/><use xlink:href="#a" transform="matrix(1,0,0,1,319.99999999999994,881.0000000000001) translate(17.994791666666664 47.994791666666664)"/><path d="M540 896c0-8.28 6.72-15 15-15h70c8.28 0 15 6.72 15 15v50c0 8.28-6.72 15-15 15h-70c-8.28 0-15-6.72-15-15z" stroke="#000" stroke-width="3" fill="#fff" fill-opacity=".48"/><use xlink:href="#a" transform="matrix(1,0,0,1,540,881.0000000000001) translate(17.994791666666664 47.994791666666664)"/><path d="M200 921h118.5" stroke="#000" stroke-width="3" fill="none"/><path d="M200 922.5v-3zM318.5 921l-14.27 4.64v-9.28z"/><path d="M320 919.9v2.2l-17.27 5.6v-13.4zm-14.27 3.67l7.92-2.57-7.92-2.57z"/><path d="M420 921h120" stroke="#000" stroke-width="3" fill="none"/><path d="M420 922.5v-3zM540 921l-14.27 4.64v-9.28z"/><path d="M540 919.42v3.16l-15.77 5.12v-13.4zm-12.77 4.15l7.92-2.57-7.92-2.57z"/><path d="M164.62 706.38c0-2.97-2.55-5.38-5.7-5.38h-17.16c-3.16 0-5.72 2.4-5.72 5.38v109.24c0 2.97 2.56 5.38 5.72 5.38h17.15c3.17 0 5.72-2.4 5.72-5.38z" stroke="#000" stroke-width="3" fill="#666" fill-opacity=".6"/><path d="M159.86 719.5c0 4.95-4.26 8.96-9.53 8.96-5.26 0-9.52-4-9.52-8.96 0-4.94 4.27-8.95 9.53-8.95 5.27 0 9.53 4 9.53 8.95z" stroke="#000" stroke-width="3"/><path d="M159.86 746.37c0 4.95-4.26 8.95-9.53 8.95-5.26 0-9.52-4-9.52-8.95 0-4.94 4.27-8.95 9.53-8.95 5.27 0 9.53 4 9.53 8.95z" stroke="#000" stroke-width="3" fill="#ccc"/><path d="M159.86 773.24c0 4.94-4.26 8.95-9.53 8.95-5.26 0-9.52-4.02-9.52-8.96 0-4.94 4.27-8.95 9.53-8.95 5.27 0 9.53 4 9.53 8.94z" stroke="#000" stroke-width="3" fill="#666"/><path d="M159.86 800.1c0 4.95-4.26 8.96-9.53 8.96-5.26 0-9.52-4-9.52-8.95 0-4.94 4.27-8.96 9.53-8.96 5.27 0 9.53 4.02 9.53 8.97z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M384.04 706.38c0-2.97-2.56-5.38-5.72-5.38h-17.15c-3.15 0-5.7 2.4-5.7 5.38v109.24c0 2.97 2.55 5.38 5.7 5.38h17.15c3.16 0 5.72-2.4 5.72-5.38z" stroke="#000" stroke-width="3" fill="#fff" fill-opacity=".6"/><path d="M379.28 719.5c0 4.95-4.27 8.96-9.53 8.96-5.27 0-9.53-4-9.53-8.96 0-4.94 4.26-8.95 9.53-8.95 5.26 0 9.53 4 9.53 8.95z" stroke="#000" stroke-width="3"/><path d="M379.28 746.37c0 4.95-4.27 8.95-9.53 8.95-5.27 0-9.53-4-9.53-8.95 0-4.94 4.26-8.95 9.53-8.95 5.26 0 9.53 4 9.53 8.95z" stroke="#000" stroke-width="3" fill="#ccc"/><path d="M379.28 773.24c0 4.94-4.27 8.95-9.53 8.95-5.27 0-9.53-4.02-9.53-8.96 0-4.94 4.26-8.95 9.53-8.95 5.26 0 9.53 4 9.53 8.94z" stroke="#000" stroke-width="3" fill="#666"/><path d="M379.28 800.1c0 4.95-4.27 8.96-9.53 8.96-5.27 0-9.53-4-9.53-8.95 0-4.94 4.26-8.96 9.53-8.96 5.26 0 9.53 4.02 9.53 8.97z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M604 706.38c0-2.97-2.5-5.38-5.58-5.38h-16.75c-3.1 0-5.6 2.4-5.6 5.38v109.24c0 2.97 2.5 5.38 5.6 5.38h16.75c3.08 0 5.58-2.4 5.58-5.38z" stroke="#000" stroke-width="3" fill="#ccc" fill-opacity=".6"/><path d="M599.35 719.5c0 4.95-4.17 8.96-9.3 8.96-5.15 0-9.3-4-9.3-8.96 0-4.94 4.15-8.95 9.3-8.95 5.13 0 9.3 4 9.3 8.95z" stroke="#000" stroke-width="3"/><path d="M599.35 746.37c0 4.95-4.17 8.95-9.3 8.95-5.15 0-9.3-4-9.3-8.95 0-4.94 4.15-8.95 9.3-8.95 5.13 0 9.3 4 9.3 8.95z" stroke="#000" stroke-width="3" fill="#ccc"/><path d="M599.35 773.24c0 4.94-4.17 8.95-9.3 8.95-5.15 0-9.3-4.02-9.3-8.96 0-4.94 4.15-8.95 9.3-8.95 5.13 0 9.3 4 9.3 8.94z" stroke="#000" stroke-width="3" fill="#666"/><path d="M599.35 800.1c0 4.95-4.17 8.96-9.3 8.96-5.15 0-9.3-4-9.3-8.95 0-4.94 4.15-8.96 9.3-8.96 5.13 0 9.3 4.02 9.3 8.97z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M590 881v-58.5" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M594.64 836.77h-9.28L590 822.5z"/><path d="M596.7 838.27h-13.4l5.6-17.27h2.2zm-9.27-3h5.14l-2.57-7.92z"/><path d="M370 881v-58.5" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M374.64 836.77h-9.28L370 822.5z"/><path d="M376.7 838.27h-13.4l5.6-17.27h2.2zm-9.27-3h5.14l-2.57-7.92z"/><path d="M150.08 881l.13-60" stroke="#000" stroke-width="3" fill="none"/><path d="M150.08 881h-1.5zM154.8 835.28l-9.26-.02L150.2 821z"/><path d="M156.88 836.78l-13.4-.03 5.15-15.75h3.15zm-9.27-3.02h5.15l-2.55-7.9z"/><path d="M561.5 620c0-11.05 8.95-20 20-20h17c11.05 0 20 8.95 20 20s-8.95 20-20 20h-17c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-width="3" fill="#d1bcd2"/><use xlink:href="#b" transform="matrix(1,0,0,1,561.5,600) translate(23.09912109375 25.396484375)"/><path d="M118.5 620c0-11.05 8.95-20 20-20h17c11.05 0 20 8.95 20 20s-8.95 20-20 20h-17c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-width="3" fill="#d1bcd2"/><use xlink:href="#b" transform="matrix(1,0,0,1,118.5,600) translate(23.09912109375 25.396484375)"/><path d="M340 620c0-11.05 8.95-20 20-20h17c11.05 0 20 8.95 20 20s-8.95 20-20 20h-17c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-width="3" fill="#d1bcd2"/><use xlink:href="#b" transform="matrix(1,0,0,1,340,600) translate(23.09912109375 25.396484375)"/><path d="M590.04 701v-59.5" stroke="#000" stroke-width="3" fill="none"/><path d="M591.54 701h-3 3zM594.68 655.77h-9.27l4.64-14.27z"/><path d="M596.74 657.27h-13.4l5.6-17.27h2.2zm-9.27-3h5.14l-2.56-7.92z"/><path d="M150.33 701v-59.5" stroke="#000" stroke-width="3" fill="none"/><path d="M151.83 701h-3 3zM154.97 655.77h-9.27l4.63-14.27z"/><path d="M157.03 657.27h-13.4l5.6-17.27h2.2zm-9.27-3h5.14l-2.57-7.92z"/><path d="M369.75 701v-59.5" stroke="#000" stroke-width="3" fill="none"/><path d="M371.25 701h-3 3zM374.38 655.77h-9.27l4.65-14.27z"/><path d="M376.45 657.27h-13.4l5.6-17.27h2.2zm-9.27-3h5.14l-2.57-7.92z"/><path d="M119 529.5c0-3.87 3.13-7 7-7h486c3.87 0 7 3.13 7 7v21c0 3.87-3.13 7-7 7H126c-3.87 0-7-3.13-7-7z" stroke="#000" stroke-width="3" fill="#e5e5e5"/><path d="M597 539.5c0 5.52-4.48 10-10 10s-10-4.48-10-10 4.48-10 10-10 10 4.48 10 10z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M380 540c0 5.52-4.48 10-10 10s-10-4.48-10-10 4.48-10 10-10 10 4.48 10 10z" stroke="#000" stroke-width="3" fill="#d1bcd2"/><path d="M158 539.5c0 5.52-4.92 10-11 10s-11-4.48-11-10 4.92-10 11-10 11 4.48 11 10z" stroke="#000" stroke-width="3" fill="#834187"/><path d="M147 600v-49" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M151.64 565.28h-9.28L147 551z"/><path d="M147 549.5l1.04-.14 5.66 17.42h-13.4l5.66-17.42zm-2.57 14.28h5.14l-2.57-7.9z"/><path d="M368.5 600v-48.72" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M373.14 565.54h-9.28l4.64-14.26z"/><path d="M369.64 549.94l5.56 17.1h-13.4l5.67-17.45zm-3.7 14.1h5.13l-2.57-7.9z"/><path d="M590 600v-49.46" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M594.64 564.8h-9.28l4.64-14.26z"/><path d="M596.7 566.3h-13.4l5.56-17.1 1.3-.2.78-.4zm-9.27-3h5.14l-2.57-7.9z"/><path d="M320 480c0-11.05 8.95-20 20-20h58c11.05 0 20 8.95 20 20s-8.95 20-20 20h-58c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-width="3" fill="#d1bcd2"/><use xlink:href="#c" transform="matrix(1,0,0,1,320,460) translate(11.19384765625 25.396484375)"/><path d="M369 522.5v-21" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M373.64 515.77h-9.28L369 501.5z"/><path d="M375.7 517.27h-13.4l5.6-17.27h2.2zm-9.27-3h5.14l-2.57-7.92z"/><path d="M120 409.5c0-3.87 3.13-7 7-7h486c3.87 0 7 3.13 7 7v21c0 3.87-3.13 7-7 7H127c-3.87 0-7-3.13-7-7z" stroke="#000" stroke-width="3" fill="#e5e5e5"/><path d="M598 419.5c0 5.52-4.48 10-10 10s-10-4.48-10-10 4.48-10 10-10 10 4.48 10 10z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M381 420c0 5.52-4.48 10-10 10s-10-4.48-10-10 4.48-10 10-10 10 4.48 10 10z" stroke="#000" stroke-width="3" fill="#d1bcd2"/><path d="M159 419.5c0 5.52-4.92 10-11 10s-11-4.48-11-10 4.92-10 11-10 11 4.48 11 10z" stroke="#000" stroke-width="3" fill="#834187"/><path d="M369 460v-21" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M373.64 453.27h-9.28L369 439z"/><path d="M375.7 454.77h-13.4l5.6-17.27h2.2zm-9.27-3h5.14l-2.57-7.92z"/><path d="M251.53 750h67.97v24h-67.97z" fill="#fff" fill-opacity="0"/><path d="M271.24 762h-8.08v8.1h-2.05V762h-8.08v-2.03h8.1v-8.1h2.04v8.1h8.08V762M305.3 755.57l-4.4 8.1v.54c0 1.5.38 3.08 1.06 3.08.43 0 .93-.6 1.58-2.3l.5.23c-.7 2.3-1.65 3.9-3.13 3.9-1.17 0-1.54-1.35-1.6-3.24-1.56 1.9-3.7 3.3-6.02 3.3-3 0-4.15-2.1-4.15-4.7 0-2.5 1.08-5.14 2.82-6.9 1.36-1.4 3.44-2.4 5.36-2.4 2.64 0 3.92 1.86 3.92 3.7l1.42-3.3h2.67m-5.88 4.84c0-2.1-.4-4.58-2.4-4.58-1.94 0-5.35 4.2-5.35 9.14 0 1.76.56 3.56 2.14 3.56 2.18 0 4.3-4.18 5.12-5.92.13-.6.5-1.36.5-2.2M301.65 752.22H292v-1.67h9.65v1.67M314.04 773.5H308v-.33c1.62-.1 2.08-.55 2.08-1.75v-9.84c0-.75-.2-1.08-.66-1.08-.22 0-.6.1-1 .27l-.58.22v-.32l3.92-2 .2.07v13.08c0 .95.44 1.34 2.08 1.34v.33"/><path d="M473.55 750.54H540V774h-66.45z" fill="#fff" fill-opacity="0"/><path d="M492.82 762.28h-7.9v7.9h-2v-7.9H475v-2h7.9v-7.9h2v7.9h7.9v2M526.12 755.98l-4.3 7.9v.55c0 1.46.37 3 1.03 3 .43 0 .9-.57 1.55-2.24l.48.2c-.66 2.24-1.6 3.82-3.06 3.82-1.15 0-1.5-1.33-1.57-3.18-1.52 1.85-3.6 3.24-5.88 3.24-2.94 0-4.06-2.06-4.06-4.6 0-2.46 1.07-5.03 2.76-6.76 1.34-1.37 3.37-2.34 5.25-2.34 2.58 0 3.82 1.82 3.82 3.6l1.4-3.2h2.6m-5.75 4.73c0-2.05-.4-4.48-2.34-4.48-1.9 0-5.24 4.12-5.24 8.94 0 1.73.54 3.48 2.08 3.48 2.12 0 4.18-4.1 5-5.78.12-.58.5-1.34.5-2.15M522.55 752.7h-9.42v-1.63h9.42v1.64M536.38 770.58l-1.16 2.93h-8.38v-.25l3.82-4.05c2-2.12 2.78-3.74 2.78-5.57 0-1.95-1.15-3.02-2.97-3.02-1.55 0-2.3.7-3.15 2.8l-.45-.1c.45-2.52 1.82-4.27 4.45-4.27 2.42 0 3.97 1.65 3.97 3.77 0 1.7-.85 3.3-2.76 5.3L529 771.9h5.02c.9 0 1.35-.23 2.06-1.43"/><path d="M80 751h30.5v23.76H80z" fill="#fff" fill-opacity="0"/><path d="M96.64 756.44l-4.3 7.9v.56c0 1.45.36 3 1.02 3 .43 0 .9-.58 1.55-2.25l.5.22c-.67 2.24-1.6 3.8-3.07 3.8-1.15 0-1.5-1.32-1.57-3.17-1.52 1.85-3.6 3.25-5.88 3.25-2.94 0-4.06-2.07-4.06-4.6 0-2.46 1.06-5.04 2.76-6.77 1.33-1.36 3.36-2.33 5.24-2.33 2.57 0 3.82 1.82 3.82 3.6l1.4-3.2h2.6m-5.76 4.72c0-2.06-.4-4.48-2.33-4.48-1.9 0-5.25 4.1-5.25 8.92 0 1.73.55 3.5 2.1 3.5 2.1 0 4.18-4.1 5-5.8.1-.57.48-1.33.48-2.15M93.06 753.17h-9.42v-1.64h9.42v1.64M106.93 766.9c0 3.7-1.35 7.38-4.84 7.38-3.67 0-4.85-4-4.85-7.5 0-3.8 1.48-7.3 4.93-7.3 2.8 0 4.75 3.03 4.75 7.43m-2.05.1c0-4.44-.95-6.95-2.83-6.95-1.78 0-2.74 2.53-2.74 6.88s.95 6.8 2.8 6.8c1.8 0 2.78-2.48 2.78-6.72"/><path d="M747.33 704.47c0-3.02-2.44-5.47-5.46-5.47h-16.4c-3.02 0-5.47 2.45-5.47 5.47v111.06c0 3.02 2.45 5.47 5.47 5.47h16.4c3.02 0 5.46-2.45 5.46-5.47z" stroke="#000" stroke-width="3" fill="#ccc" fill-opacity=".6"/><path d="M742.78 717.8c0 5.04-4.08 9.1-9.1 9.1-5.05 0-9.12-4.06-9.12-9.1 0-5 4.07-9.1 9.1-9.1 5.04 0 9.12 4.1 9.12 9.1z" stroke="#000" stroke-width="3"/><path d="M742.78 745.13c0 5.02-4.08 9.1-9.1 9.1-5.05 0-9.12-4.08-9.12-9.1 0-5.03 4.07-9.1 9.1-9.1 5.04 0 9.12 4.07 9.12 9.1z" stroke="#000" stroke-width="3" fill="#ccc"/><path d="M742.78 772.44c0 5.03-4.08 9.1-9.1 9.1-5.05 0-9.12-4.07-9.12-9.1 0-5.02 4.07-9.1 9.1-9.1 5.04 0 9.12 4.08 9.12 9.1z" stroke="#000" stroke-width="3" fill="#666"/><path d="M742.78 799.76c0 5.03-4.08 9.1-9.1 9.1-5.05 0-9.12-4.07-9.12-9.1 0-5.03 4.07-9.1 9.1-9.1 5.04 0 9.12 4.07 9.12 9.1z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M1138 1113.64h13.47v14.72H1138z" fill="#fff" fill-opacity="0"/><path d="M1148.6 1124.27l.5.3c-1.86 2.34-3.46 3.28-5.74 3.28-2.8 0-4.45-1.58-4.45-4.67 0-2.82 1.58-5.45 3.74-7.18 1.48-1.18 3.2-1.85 5.06-1.85 1.84 0 3.18 1.03 3.18 2.46 0 .82-.67 1.46-1.46 1.46-.84 0-1.18-.6-1.18-1.2 0-.56.46-.9.46-1.47 0-.37-.43-.6-1.12-.6-1.22 0-2.43.53-3.3 1.44-1.7 1.8-2.77 4.37-2.77 7.06 0 2.18.98 3.46 2.7 3.46 1.62 0 2.77-.76 4.4-2.5"/><path d="M32 980h227v39H32z" stroke="#000" stroke-opacity="0" stroke-width="3" fill="#fff" fill-opacity="0"/><use xlink:href="#d" transform="matrix(1,0,0,1,37,985) translate(59.89208984375 19.896484375)"/><path d="M782 881c0-11.05 8.95-20 20-20h458c11.05 0 20 8.95 20 20v118c0 11.05-8.95 20-20 20H802c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-opacity="0" stroke-width=".5" fill="#d1bcd2" fill-opacity=".3"/><path d="M806.14 896c0-8.28 6.72-15 15-15h70c8.3 0 15 6.72 15 15v50c0 8.28-6.7 15-15 15h-70c-8.28 0-15-6.72-15-15z" stroke="#000" stroke-width="3" fill="#fff" fill-opacity=".48"/><use xlink:href="#a" transform="matrix(1,0,0,1,806.1409685527294,881) translate(17.994791666666664 47.994791666666664)"/><path d="M1038 896c0-8.28 6.72-15 15-15h70c8.28 0 15 6.72 15 15v50c0 8.28-6.72 15-15 15h-70c-8.28 0-15-6.72-15-15z" stroke="#000" stroke-width="3" fill="#fff" fill-opacity=".48"/><use xlink:href="#a" transform="matrix(1,0,0,1,1038,881) translate(17.994791666666664 47.994791666666664)"/><path d="M906.14 921H1038" stroke="#000" stroke-width="3" fill="none"/><path/><path d="M1038 921l-14.27 4.64v-9.28z"/><path d="M1038 919.42v3.16l-15.77 5.12v-13.4zm-12.77 4.15l7.92-2.57-7.92-2.57z"/><path d="M820 1250c0-5.52 4.48-10 10-10h122c5.52 0 10 4.48 10 10v20c0 5.52-4.48 10-10 10H830c-5.52 0-10-4.48-10-10z" stroke="#000" stroke-width="2" fill="#fff" fill-opacity="0"/><use xlink:href="#e" transform="matrix(1,0,0,1,825,1245) translate(14.658311631944443 22.32855902777778)"/><path d="M1102.58 1208.88c0-2.97-2.55-5.38-5.7-5.38h-17.16c-3.16 0-5.72 2.4-5.72 5.38v109.24c0 2.97 2.56 5.38 5.72 5.38h17.15c3.16 0 5.7-2.4 5.7-5.38z" stroke="#000" stroke-width="3" fill="#fff" fill-opacity=".6"/><path d="M1097.82 1222c0 4.95-4.26 8.96-9.53 8.96s-9.54-4-9.54-8.96c0-4.94 4.27-8.95 9.53-8.95s9.52 4 9.52 8.95z" stroke="#000" stroke-width="3"/><path d="M1097.82 1248.87c0 4.95-4.26 8.95-9.53 8.95s-9.54-4-9.54-8.95c0-4.94 4.27-8.95 9.53-8.95s9.52 4 9.52 8.95z" stroke="#000" stroke-width="3" fill="#ccc"/><path d="M1097.82 1275.74c0 4.94-4.26 8.95-9.53 8.95s-9.54-4.02-9.54-8.96c0-4.94 4.27-8.95 9.53-8.95s9.52 4 9.52 8.94z" stroke="#000" stroke-width="3" fill="#666"/><path d="M1097.82 1302.6c0 4.95-4.26 8.96-9.53 8.96s-9.54-4-9.54-8.95c0-4.94 4.27-8.96 9.53-8.96s9.52 4.02 9.52 8.97z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M1087.6 1060l.4-99" stroke="#000" stroke-width="3" fill="none"/><path d="M1087.6 1060h-1.5zM1092.58 975.28l-9.27-.03L1088 961z"/><path d="M1094.64 976.8l-13.4-.06 5.18-15.74h3.16zm-9.26-3.04l5.14.02-2.54-7.93z"/><path d="M735 980h227v39H735z" stroke="#000" stroke-opacity="0" stroke-width="3" fill="#fff" fill-opacity="0"/><use xlink:href="#f" transform="matrix(1,0,0,1,740,985) translate(59.89208984375 19.896484375)"/><path d="M856.14 881l-.27-12.9-.8-12.75-1.32-12.54-1.82-12.32-2.3-12.08-2.77-11.82-3.22-11.53-3.65-11.23-4.06-10.9-4.44-10.55-4.8-10.2-5.13-9.82-5.46-9.45-5.74-9.06-6.02-8.67-6.28-8.27-6.52-7.88-6.73-7.48-6.94-7.1-7.13-6.7-7.32-6.3-7.48-5.95-7.65-5.57-7.8-5.2-7.98-4.8-8.13-4.47-8.27-4.1-8.43-3.76-8.6-3.4-8.74-3.05-8.92-2.7-9.1-2.33-9.28-1.98-9.5-1.6-9.7-1.23-9.94-.82-10.2-.43-5.18-.05" stroke="#000" stroke-width="3" fill="none"/><path d="M857.64 881h-1.66l1.66-.04zM632.62 625.07L618.5 620l14.4-4.2z"/><path d="M634.05 627.18l-15.74-5.65.2-1.53-.05-1.44-.02-.1 16.04-4.67zm-10.7-7.03l7.83 2.8.16-5.12z"/><path d="M640.08 758.4h15.7v9.6h-15.7z" fill="#fff" fill-opacity="0"/><path d="M654.68 760.3h-13.5v-1.5h13.5v1.5m0 4.58h-13.5v-1.5h13.5v1.5"/><path d="M371 430l-7.1 2.47-6.37 2.52-5.76 2.55-5.23 2.6-4.8 2.63-4.4 2.66-4.06 2.7-3.78 2.75-3.5 2.77-3.3 2.84-3.08 2.9-2.9 2.97-2.75 3.04-2.6 3.14-2.44 3.24-2.33 3.35-2.22 3.5-2.1 3.64-2 3.82-1.9 4.03-1.8 4.3-1.7 4.56-1.6 4.9-1.48 5.3-1.36 5.8-1.22 6.42-1.05 7.16-.85 8.13-.6 9.46-.22 11.33.3 14.37 1.34 20.62 10.3 105.25.3 14.26-.07 7" fill="none"/><path d="M371 430l-4.23 1.47m-5.6 2.08l-3.64 1.44-4.6 2.04m-5.37 2.6l-1.02.5-4.8 2.64-2 1.2m-5.03 3.22l-1.42.95-3.78 2.74-2 1.58m-4.58 3.84l-.22.2-3.08 2.9-2.9 2.95-.2.2m-3.92 4.5l-1.22 1.47-2.45 3.24-1.7 2.45m-3.22 5.03l-1.72 3-2 3.83-.5 1.04m-2.43 5.45l-.77 1.82-1.7 4.57-.65 1.98m-1.73 5.7l-.7 2.53-1.36 5.8-.07.38m-1.1 5.86l-.05.18-1.05 7.16-.16 1.53m-.6 5.94l-.08.67-.52 8.28m-.17 5.96l-.13 6.55.05 2.4m.13 5.96l.13 6 .2 2.94m.4 5.96l.56 8.93m.5 5.94l.86 8.9m.58 5.95l.88 8.9m.58 5.94l.87 8.9m.58 5.95l.88 8.9m.58 5.94l.87 8.9m.58 5.95l.9 8.9m.57 5.93l.87 8.9m.44 5.96l.2 8.94m.04 5.97l-.05 4.5" stroke="#000" stroke-width="3" fill="none"/><path d="M374.33 430.36l-2.8 1.05-.53-1.4 3.02-.5z"/><path d="M298.67 719l-4.72-14.25 9.27-.06z" stroke="#000" stroke-width="3"/><path d="M588 429.5l-6.9 3.86-6.18 3.8-5.6 3.78-5.07 3.75-4.64 3.73-4.25 3.73-3.93 3.75-3.64 3.8-3.4 3.8-3.15 3.88-2.95 3.96-2.77 4.05-2.6 4.16-2.44 4.32-2.3 4.48-2.16 4.7-2.03 4.94-1.9 5.25-1.78 5.62-1.65 6.06-1.5 6.63-1.34 7.35-1.15 8.3-.93 9.62-.63 11.57-.2 14.9.72 22.93 5.46 99.15-.23 19.03-.18 4.6" fill="none"/><path d="M588 429.5l-3.97 2.22m-5.24 3.06l-3.88 2.4-3.77 2.53m-4.93 3.54l-1.97 1.45-4.64 3.73-.5.45m-4.53 4.03l-3.15 3-3.3 3.43m-4.02 4.53l-2.87 3.52-2.72 3.65m-3.4 5.02l-2.2 3.5-2.43 4.32m-2.73 5.4l-1.74 3.8-1.88 4.55m-2.08 5.7l-1.75 5.55-.87 3.16m-1.46 5.88l-.82 3.66-.96 5.27m-.94 6l-.6 4.38-.46 4.65m-.53 6.04l-.5 9.07m-.13 6.06l-.1 9.1m.12 6.05l.28 9.1m.2 6.05l.08 2.9.34 6.2m.33 6.04l.5 9.08m.33 6.06l.5 9.1m.33 6.04l.5 9.08m.34 6.06l.5 9.08m.33 6.05l.5 9.1m.33 6.05l.5 9.08m.07 6.06l-.1 9.08m-.08 6.06l-.18 4.55" stroke="#000" stroke-width="3" fill="none"/><path d="M591.34 429.28l-2.6 1.52-.74-1.3 3.16-.5v-.02z"/><path d="M518.67 719l-4.34-14.37 9.27.2z" stroke="#000" stroke-width="3"/><path d="M20 340h330v42.5H20z" stroke="#000" stroke-opacity="0" stroke-width="3" fill="#fff" fill-opacity="0"/><use xlink:href="#g" transform="matrix(1,0,0,1,25,345) translate(46.58154296875 21.896484375)"/><use xlink:href="#h" transform="matrix(1,0,0,1,25,345) translate(165.40087890625 21.896484375)"/><path d="M148 429.5l-4.97 2.4-4.55 2.44-4.2 2.47-3.88 2.53-3.62 2.57-3.37 2.6-3.16 2.7-2.98 2.73-2.82 2.8-2.67 2.9-2.54 3-2.42 3.13-2.3 3.24-2.2 3.4-2.12 3.57-2.02 3.77-1.94 4-1.86 4.3-1.77 4.6-1.7 5.02-1.6 5.5-1.5 6.07-1.36 6.82-1.24 7.8-1.05 9.12-.8 11.02-.45 14.1.24 20.4 5.76 124.93-.58 18.6-.32 5.3" fill="none"/><path d="M148 429.5l-4.1 1.98m-5.4 2.84l-.02.02-4.2 2.47-3.53 2.3m-4.94 3.55l-2.4 1.86-3.16 2.7-1.43 1.3m-4.35 4.23l-2.68 2.9-2.54 3-.76 1m-3.6 4.88l-.37.5-2.2 3.4-2.12 3.57-.14.27m-2.8 5.4l-1.02 2.1-1.86 4.3-.75 1.97m-2.05 5.73l-.65 1.93-1.6 5.5-.32 1.32m-1.4 5.9l-1.14 5.67-.53 3.3m-.88 6.02l-.87 7.6-.1 1.47m-.45 6.07l-.26 3.5-.17 5.62m-.2 6.07l-.07 2.4.08 6.7m.07 6.1l.1 7.6.06 1.5m.3 6.1l.4 9.1m.3 6.08l.4 9.1m.3 6.08l.4 9.12m.3 6.07l.4 9.1m.3 6.1l.4 9.1m.3 6.07l.4 9.12m.3 6.07l.4 9.12m.3 6.08l.4 9.1m-.03 6.1l-.3 9.1m-.2 6.08l-.27 4.55" stroke="#000" stroke-width="3" fill="none"/><path d="M151.35 429.42l-2.65 1.4-.7-1.32 3.12-.4.05-.03z"/><path d="M88 723.33l-4.04-14.44 9.26.37z" stroke="#000" stroke-width="3"/><path d="M1088 881v-47" stroke="#000" stroke-width="3" fill="none"/><path d="M1089.5 881h-3 3zM1092.64 848.27h-9.28L1088 834z"/><path d="M1094.7 849.77h-13.4l5.12-15.77h3.16zm-9.27-3h5.14l-2.57-7.92z"/><path d="M1060 811c0-11.05 8.95-20 20-20h16c11.05 0 20 8.95 20 20v3c0 11.05-8.95 20-20 20h-16c-11.05 0-20-8.95-20-20z" stroke="#000" stroke-width="3" fill="#d1bcd2"/><use xlink:href="#i" transform="matrix(1,0,0,1,1060,791) translate(22.59912109375 26.896484375)"/><path d="M1088 791l1-40" fill="none"/><path d="M1088 791l.1-4m.13-5.33l.2-8m.14-5.34l.2-8m.13-5.33l.1-4" stroke="#000" stroke-width="3" fill="none"/><path d="M1088.02 791h-1.52v-.04z"/><path d="M1089 751l4.28 14.38-9.27-.23z" stroke="#000" stroke-width="3"/><path d="M1101 1074.27c0-3.02-2.45-5.47-5.47-5.47h-16.4c-3.02 0-5.46 2.45-5.46 5.47v111.06c0 3.02 2.44 5.47 5.46 5.47h16.4c3.02 0 5.47-2.45 5.47-5.47z" stroke="#000" stroke-width="3" fill="#ccc" fill-opacity=".6"/><path d="M1096.44 1087.6c0 5.04-4.07 9.1-9.1 9.1-5.04 0-9.12-4.06-9.12-9.1 0-5 4.08-9.1 9.1-9.1 5.05 0 9.12 4.1 9.12 9.1z" stroke="#000" stroke-width="3"/><path d="M1096.44 1114.93c0 5.02-4.07 9.1-9.1 9.1-5.04 0-9.12-4.08-9.12-9.1 0-5.03 4.08-9.1 9.1-9.1 5.05 0 9.12 4.07 9.12 9.1z" stroke="#000" stroke-width="3" fill="#ccc"/><path d="M1096.44 1142.24c0 5.03-4.07 9.1-9.1 9.1-5.04 0-9.12-4.07-9.12-9.1 0-5.02 4.08-9.1 9.1-9.1 5.05 0 9.12 4.08 9.12 9.1z" stroke="#000" stroke-width="3" fill="#666"/><path d="M1096.44 1169.56c0 5.03-4.07 9.1-9.1 9.1-5.04 0-9.12-4.07-9.12-9.1 0-5.03 4.08-9.1 9.1-9.1 5.05 0 9.12 4.07 9.12 9.1z" stroke="#000" stroke-width="3" fill="#fff"/><path d="M733.67 821l.72 35.67 1.88 30.3 2.7 25.75 3.23 21.96 3.6 18.85 3.8 16.3 3.95 14.16 4.03 12.4 4.07 10.94 4.07 9.7 4.07 8.66 4.04 7.76 4.04 7 4 6.32 4 5.75 4 5.25 3.96 4.8 3.97 4.4 3.98 4.07 4 3.74.22.2 4.1 3.53 4.38 3.45 4.66 3.36 4.98 3.3 5.35 3.22 5.8 3.16 6.27 3.1 6.88 3.03 7.56 2.97 8.4 2.9 9.44 2.82 10.7 2.72 12.38 2.6 14.6 2.4 17.8 2.2 23.04 1.86 34.5 1.3 73.56.08" fill="none"/><path d="M733.67 821l.1 4.47m.1 5.95l.2 8.92m.1 5.95l.2 8.92m.3 5.94l.56 8.9m.37 5.95l.56 8.92m.53 5.93l.92 8.87m.62 5.92l.74 7.08.26 1.8m.87 5.88l1.3 8.83m.9 5.9l1.66 8.76m1.1 5.84l.73 3.8 1.15 4.92m1.35 5.8l1.3 5.56.87 3.1m1.6 5.73l1.48 5.34 1.05 3.2m1.84 5.67l1.14 3.53 1.82 4.9m2.07 5.57l.18.47 3.26 7.76m2.46 5.43l2.43 5.17 1.48 2.85m2.77 5.26l3.83 6.65.68 1.07m3.18 5.02l.15.24 4 5.75.98 1.3m3.63 4.73l3.34 4.02 2.48 2.75m4.1 4.32l1.36 1.4 4 3.74.22.2.9.78m4.57 3.82l3 2.38 4.13 2.98m4.95 3.3l.57.37 5.35 3.23 1.76.95m5.25 2.82l5.06 2.5 3 1.32m5.48 2.34l5.96 2.34 2.38.82m5.63 1.95l.4.12 8.14 2.44m5.75 1.52l6.23 1.58 2.44.5m5.82 1.23l4.1.85 4.67.77m5.87.98l4.06.67 4.77.6m5.9.72l7.14.86 1.75.14m5.93.48l8.9.72m5.93.47l.54.05 8.4.3m5.94.24l8.92.33m5.95.2l5.3.2 3.62.02m5.95 0h8.93m5.95.02h8.93m5.95.02h8.93m5.96.02h8.92m5.96 0l4.46.02" stroke="#000" stroke-width="3" fill="none"/><path d="M732.17 821.03V821h1.63zM1060.4 1123l-14.27 4.62v-9.27z"/><path d="M1060.4 1121.42v3.16l-15.77 5.1v-13.4zm-12.77 4.14l7.92-2.57-7.9-2.6z"/><path d="M962 1260h110.5" stroke="#000" stroke-width="3" fill="none"/><path d="M962 1261.5v-3zM1072.5 1260l-14.27 4.64v-9.28z"/><path d="M1074 1258.9v2.2l-17.27 5.6v-13.4zm-14.27 3.67l7.92-2.57-7.92-2.57z"/><defs><path d="M237 0v-1349h191v1193h672V0H237" id="j"/><path d="M614-1226c-167 1-283 53-283 213 0 183 186 193 334 234 230 63 463 120 463 409 0 286-219 387-518 390C309 23 131-98 79-338l185-37c34 165 149 248 351 246 184-2 324-58 324-238 0-203-207-221-372-266-210-57-422-111-422-377 0-267 201-356 470-360 279-5 430 101 480 324l-188 33c-28-141-121-215-293-213" id="k"/><path d="M709-1193V0H519v-1193H76v-156h1076v156H709" id="l"/><path d="M285-1169c8 382 2 780 4 1169H129v-1349h237c86 239 188 461 253 720 69-258 169-481 255-720h225V0H937c2-390-5-788 6-1169-75 255-170 488-259 729H547c-90-240-185-475-262-729" id="m"/><g id="a"><use transform="matrix(0.013020833333333334,0,0,0.013020833333333334,0,0)" xlink:href="#j"/><use transform="matrix(0.013020833333333334,0,0,0.013020833333333334,16.002604166666668,0)" xlink:href="#k"/><use transform="matrix(0.013020833333333334,0,0,0.013020833333333334,32.005208333333336,0)" xlink:href="#l"/><use transform="matrix(0.013020833333333334,0,0,0.013020833333333334,48.0078125,0)" xlink:href="#m"/></g><path d="M839-1335c-182-6-269 67-259 253h491v142H580V0H400v-940H138v-142h262c-15-293 132-408 418-402 94 2 200 7 281 21v145c-75-10-177-14-260-17" id="n"/><use transform="matrix(0.0087890625,0,0,0.0087890625,0,0)" xlink:href="#n" id="b"/><path d="M873-819c-18-114-119-146-250-146-163 0-245 50-245 151 0 151 170 148 294 185 182 54 388 94 388 320 0 240-189 325-439 329-245 4-410-69-454-268l159-31c24 133 136 168 295 165 144-2 270-31 270-171 0-164-195-160-331-202-167-52-350-87-350-299 0-218 173-315 413-313 220 2 373 77 412 260" id="o"/><path d="M615-1102c343 0 484 203 482 560-1 347-147 562-488 562-336 0-475-219-479-562-4-349 156-560 485-560zm-8 989c240 0 301-180 301-429 0-245-55-427-290-427-236 0-299 181-299 427 0 243 61 429 288 429" id="p"/><path d="M682 16c-209 0-323-80-324-285v-671H190v-142h170l58-282h120v282h432v142H538v652c2 114 60 155 182 155 106 0 209-16 297-34v137C921-4 806 16 682 16" id="q"/><path d="M904-1102c199 0 220 177 220 381V0H956v-686c-3-114 0-215-60-264-70-33-125-4-158 71-26 56-39 140-39 252V0H531v-686c-3-114-1-215-61-264-78-41-136 24-157 84-24 69-39 159-39 259V0H105c-3-360 6-732-6-1082h149c6 50 3 123 8 175 36-100 83-195 216-195 135 0 166 79 196 196 42-105 93-196 236-196" id="r"/><path d="M1000-272c3 95 12 159 101 161 21 0 41-3 59-7V-6c-44 10-86 16-139 16-141 2-191-84-197-217h-6C748-76 648 20 446 20c-207 0-318-120-318-322 0-266 194-348 454-354l236-4c12-191-40-305-222-305-140 0-220 47-232 172l-188-17c33-204 181-292 423-292 255 0 401 118 401 364v466zm-683-27c0 109 63 184 175 182 166-3 259-96 306-217 24-65 20-120 20-200-232 7-501-28-501 235" id="s"/><path d="M932 0L611-444 288 0H94l415-556-397-526h199l300 421 298-421h201L713-558 1133 0H932" id="t"/><g id="c"><use transform="matrix(0.0087890625,0,0,0.0087890625,0,0)" xlink:href="#o"/><use transform="matrix(0.0087890625,0,0,0.0087890625,10.8017578125,0)" xlink:href="#p"/><use transform="matrix(0.0087890625,0,0,0.0087890625,21.603515625,0)" xlink:href="#n"/><use transform="matrix(0.0087890625,0,0,0.0087890625,32.4052734375,0)" xlink:href="#q"/><use transform="matrix(0.0087890625,0,0,0.0087890625,43.20703125,0)" xlink:href="#r"/><use transform="matrix(0.0087890625,0,0,0.0087890625,54.0087890625,0)" xlink:href="#s"/><use transform="matrix(0.0087890625,0,0,0.0087890625,64.810546875,0)" xlink:href="#t"/></g><path d="M621-530c0 421 127 700 301 955H641C466 173 344-110 344-531s122-702 297-953h281c-174 254-301 534-301 954" id="u"/><path d="M1113-274C1038-96 884 20 626 20c-352 0-526-209-526-566 0-358 185-556 530-556 358 0 496 251 499 615H395c5 180 68 319 245 319 102 0 186-45 208-129zM857-663c-6-177-128-307-315-247-94 30-141 121-145 247h460" id="v"/><path d="M768-1103c247 0 336 167 336 416V0H824v-619c-3-164-24-273-171-273-164 0-229 142-229 312V0H143c-4-359 9-736-8-1082h268c7 63 12 146 13 215h4c67-145 160-236 348-236" id="w"/><path d="M1109-360C1066-122 902 20 624 20c-347 0-514-209-514-555 0-353 168-567 518-567 270 0 425 136 473 361l-283 14c-16-106-75-183-196-182-75 0-130 31-165 93s-52 152-52 270c0 249 74 374 221 374 120 0 188-82 201-201" id="x"/><path d="M616-1102c361 0 521 202 521 560 0 354-171 562-527 562C259 20 92-192 92-542c0-351 169-560 524-560zm-9 930c200-2 236-165 236-370 0-199-27-367-223-367-195 0-233 146-233 367 0 129 18 223 55 282s92 88 165 88" id="y"/><path d="M802-909c-3-189-2-383-2-575h281v1248c-1 83 4 168 8 236H817c-9-50-14-117-15-176h-4C735-49 651 20 482 20 191 20 97-238 97-539c0-243 66-432 221-519 50-28 108-42 175-42 162 2 253 78 309 191zm-70 658c91-113 93-462 2-584-46-61-145-100-224-53-96 56-119 190-120 349 0 123 17 214 52 275 46 82 130 115 222 74 25-12 46-33 68-61" id="z"/><path d="M875-1102c70 0 148 7 206 17v237c-110-17-267-37-359 15-123 69-192 207-192 395V0H250c-10-367 32-789-52-1082h271c19 69 36 149 46 228h4c52-151 151-250 356-248" id="A"/><path d="M885-531c0 421-122 704-297 956H307c174-255 301-534 301-955 0-420-127-700-301-954h281c175 251 297 532 297 953" id="B"/><g id="d"><use transform="matrix(0.0087890625,0,0,0.0087890625,0,0)" xlink:href="#u"/><use transform="matrix(0.0087890625,0,0,0.0087890625,10.8017578125,0)" xlink:href="#v"/><use transform="matrix(0.0087890625,0,0,0.0087890625,21.603515625,0)" xlink:href="#w"/><use transform="matrix(0.0087890625,0,0,0.0087890625,32.4052734375,0)" xlink:href="#x"/><use transform="matrix(0.0087890625,0,0,0.0087890625,43.20703125,0)" xlink:href="#y"/><use transform="matrix(0.0087890625,0,0,0.0087890625,54.0087890625,0)" xlink:href="#z"/><use transform="matrix(0.0087890625,0,0,0.0087890625,64.810546875,0)" xlink:href="#v"/><use transform="matrix(0.0087890625,0,0,0.0087890625,75.6123046875,0)" xlink:href="#A"/><use transform="matrix(0.0087890625,0,0,0.0087890625,86.4140625,0)" xlink:href="#B"/></g><path d="M934-1102c199 0 220 177 220 381V0H926c-2-260 10-533-4-785-4-72-14-138-83-138-34 0-61 27-81 81s-29 134-29 241V0H501c-2-260 9-533-5-785-4-72-13-138-82-138-46 0-65 47-80 93-21 67-30 155-30 248V0H75c-3-360 6-732-6-1082h209c6 50 3 123 8 175 36-100 83-195 216-195 135 0 166 79 196 196 42-105 93-196 236-196" id="C"/><path d="M711 13c-250 0-386-99-385-349l2-556H161v-190h181l88-282h176v282h385v190H606v530c-10 130 45 186 174 184 91-2 176-11 255-27v186C933-1 833 13 711 13" id="D"/><g id="e"><use transform="matrix(0.01193576388888889,0,0,0.01193576388888889,0,0)" xlink:href="#x"/><use transform="matrix(0.01193576388888889,0,0,0.01193576388888889,14.669053819444446,0)" xlink:href="#y"/><use transform="matrix(0.01193576388888889,0,0,0.01193576388888889,29.338107638888893,0)" xlink:href="#C"/><use transform="matrix(0.01193576388888889,0,0,0.01193576388888889,44.00716145833334,0)" xlink:href="#C"/><use transform="matrix(0.01193576388888889,0,0,0.01193576388888889,58.676215277777786,0)" xlink:href="#v"/><use transform="matrix(0.01193576388888889,0,0,0.01193576388888889,73.34526909722223,0)" xlink:href="#w"/><use transform="matrix(0.01193576388888889,0,0,0.01193576388888889,88.01432291666667,0)" xlink:href="#D"/></g><g id="f"><use transform="matrix(0.0087890625,0,0,0.0087890625,0,0)" xlink:href="#u"/><use transform="matrix(0.0087890625,0,0,0.0087890625,10.8017578125,0)" xlink:href="#z"/><use transform="matrix(0.0087890625,0,0,0.0087890625,21.603515625,0)" xlink:href="#v"/><use transform="matrix(0.0087890625,0,0,0.0087890625,32.4052734375,0)" xlink:href="#x"/><use transform="matrix(0.0087890625,0,0,0.0087890625,43.20703125,0)" xlink:href="#y"/><use transform="matrix(0.0087890625,0,0,0.0087890625,54.0087890625,0)" xlink:href="#z"/><use transform="matrix(0.0087890625,0,0,0.0087890625,64.810546875,0)" xlink:href="#v"/><use transform="matrix(0.0087890625,0,0,0.0087890625,75.6123046875,0)" xlink:href="#A"/><use transform="matrix(0.0087890625,0,0,0.0087890625,86.4140625,0)" xlink:href="#B"/></g><path d="M775-193C708-75 621 20 439 20 226 20 106-93 106-306c0-251 170-341 417-346l223-4c4-143-12-264-148-264-103 0-141 58-150 153l-293-14c37-219 194-321 455-321 263 0 418 130 417 390v392c1 84 5 161 89 160 21 0 42-2 62-6v152c-57 15-108 27-180 26-145 0-202-73-217-205h-6zm-256 17c168 0 234-139 227-325-166 4-347-25-347 173 0 94 33 152 120 152" id="E"/><path d="M794-190h353V0H118v-190h395v-702H223v-190h571v892zM513-1277v-207h281v207H513" id="F"/><g id="g"><use transform="matrix(0.0087890625,0,0,0.0087890625,0,0)" xlink:href="#u"/><use transform="matrix(0.0087890625,0,0,0.0087890625,10.8017578125,0)" xlink:href="#E"/><use transform="matrix(0.0087890625,0,0,0.0087890625,21.603515625,0)" xlink:href="#D"/><use transform="matrix(0.0087890625,0,0,0.0087890625,32.4052734375,0)" xlink:href="#D"/><use transform="matrix(0.0087890625,0,0,0.0087890625,43.20703125,0)" xlink:href="#v"/><use transform="matrix(0.0087890625,0,0,0.0087890625,54.0087890625,0)" xlink:href="#w"/><use transform="matrix(0.0087890625,0,0,0.0087890625,64.810546875,0)" xlink:href="#D"/><use transform="matrix(0.0087890625,0,0,0.0087890625,75.6123046875,0)" xlink:href="#F"/><use transform="matrix(0.0087890625,0,0,0.0087890625,86.4140625,0)" xlink:href="#y"/><use transform="matrix(0.0087890625,0,0,0.0087890625,97.2158203125,0)" xlink:href="#w"/></g><path d="M424-1484c-2 206 5 424-8 618h4c67-145 160-234 348-236 251-3 335 167 336 416V0H824v-621c0-150-23-276-173-270-163 7-227 142-227 312V0H143v-1484h281" id="G"/><path d="M622-916c-112 2-200 14-200 111 0 90 89 101 168 121 234 58 514 77 514 368C1104-4 751 54 434 5 267-21 161-112 121-270l247-37c24 111 113 145 252 141 114-3 226-12 226-124 0-101-103-113-192-134-225-54-490-76-490-351 0-247 201-328 458-328 245 0 413 88 457 292l-249 26c-16-98-92-133-208-131" id="H"/><g id="h"><use transform="matrix(0.0087890625,0,0,0.0087890625,0,0)" xlink:href="#C"/><use transform="matrix(0.0087890625,0,0,0.0087890625,10.8017578125,0)" xlink:href="#v"/><use transform="matrix(0.0087890625,0,0,0.0087890625,21.603515625,0)" xlink:href="#x"/><use transform="matrix(0.0087890625,0,0,0.0087890625,32.4052734375,0)" xlink:href="#G"/><use transform="matrix(0.0087890625,0,0,0.0087890625,43.20703125,0)" xlink:href="#E"/><use transform="matrix(0.0087890625,0,0,0.0087890625,54.0087890625,0)" xlink:href="#w"/><use transform="matrix(0.0087890625,0,0,0.0087890625,64.810546875,0)" xlink:href="#F"/><use transform="matrix(0.0087890625,0,0,0.0087890625,75.6123046875,0)" xlink:href="#H"/><use transform="matrix(0.0087890625,0,0,0.0087890625,86.4140625,0)" xlink:href="#C"/><use transform="matrix(0.0087890625,0,0,0.0087890625,97.2158203125,0)" xlink:href="#B"/></g><path d="M1048-32c-2 300-135 456-433 456-222-1-358-88-400-267l184-25c22 99 100 157 222 156 184-2 248-125 248-315 0-64 3-133-2-194C807-100 706-13 524-12c-306 0-381-228-381-537 0-318 85-550 400-550 164 0 271 83 325 202h3c1-60 3-134 12-185h171c-13 339-4 702-6 1050zM585-145c210-8 284-178 284-406 0-192-52-331-177-392-33-16-69-22-104-22-223 2-259 184-259 414 0 229 31 415 256 406" id="I"/><use transform="matrix(0.0087890625,0,0,0.0087890625,0,0)" xlink:href="#I" id="i"/></defs></g></svg>)\n",
        "\n",
        "ref: https://guillaumegenthial.github.io/sequence-to-sequence.html"
      ],
      "metadata": {
        "id": "5x6nSO3J0Kvy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoder layer:**"
      ],
      "metadata": {
        "id": "P280QZRsrEaC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Kb4esWRNSUg"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    '''class that enocodes input sentence using lstm and returns encoded vector of shape [batch_size,input_length,lstm_units]'''\n",
        "    def __init__(self, vocab_size, embedding_dim_enc, input_length, enc_units, dropout=0.0, recurrent_dropout=0.0):\n",
        "      super().__init__()\n",
        "      self.vocab_size = vocab_size\n",
        "      self.embedding_dim_enc = embedding_dim_enc\n",
        "      self.input_length = input_length\n",
        "      self.enc_units= enc_units\n",
        "      self.dropout = dropout \n",
        "      self.recurrent_dropout = recurrent_dropout \n",
        "\n",
        "    def get_config(self):\n",
        "      config = super().get_config()\n",
        "      config.update({'vocab_size': self.vocab_size, 'embedding_dim_enc': self.embedding_dim_enc,\\\n",
        "                     'input_length': self.input_length, 'enc_units': self.enc_units})\n",
        "      return config\n",
        "\n",
        "    def build(self, input_shape):\n",
        "      self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim_enc, input_length=self.input_length,\n",
        "                          mask_zero=True, name=\"embedding_layer_encoder\") \n",
        "      self.lstm = LSTM(self.enc_units, return_state=True, return_sequences=True,dropout=self.dropout,\\\n",
        "                        recurrent_dropout=self.recurrent_dropout ,name=\"Encoder_LSTM\")\n",
        "      \n",
        "    def call(self, input_sentances, training=True):\n",
        "      '''input sentence is embeded and then passed to lstm'''\n",
        "      input_embedd = self.embedding(input_sentances) # [b, max_len, embed-size]\n",
        "      self.lstm_output, _, _ = self.lstm(input_embedd) # [b, max_len, lstm-units], \n",
        "      return self.lstm_output\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "      '''Given a batch size it will return intial hidden state and intial cell state'''\n",
        "      return tf.zeros([batch_size, self.enc_units ]), tf.zeros([batch_size, self.enc_units ])\n",
        "\n",
        "    def get_states(self):\n",
        "      return self.lstm_state_h, self.lstm_state_c"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking code\n",
        "\n",
        "vocab_size = 150\n",
        "embedding_dim_enc = 50\n",
        "input_length = 10\n",
        "enc_units= 32\n",
        "dropout = 0.3\n",
        "recurrent_dropout = 0.3\n",
        "batch_size = 16\n",
        "\n",
        "input_sentances = tf.random.uniform(shape=[batch_size,input_length])\n",
        "\n",
        "e = Encoder(vocab_size, embedding_dim_enc, input_length, enc_units, dropout, recurrent_dropout)\n",
        "e(input_sentances).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WabI2lairy-n",
        "outputId": "b46752f1-4789-4c89-8d8f-dde1b49ff04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 10, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Attention Mechanism Layer:**"
      ],
      "metadata": {
        "id": "qAjT4vcjrb52"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab5SNdPZLlur"
      },
      "outputs": [],
      "source": [
        "class AttentionMechanism(tf.keras.layers.Layer):\n",
        "  '''Class the calculates attention weights and corresponding weighted vector using simple dot product operation.'''\n",
        "  def __init__(self, initializer = tf.keras.initializers.GlorotUniform() ):\n",
        "    super().__init__()\n",
        "    self.initializer = initializer\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({'initializer': self.initializer })\n",
        "    return config\n",
        "\n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    '''decoder input is transformed to match encoder output dimension and attention weights are calculated\n",
        "    based on similarity using dot products and weighted sum of encoder hidden state vector is returned as context vector\n",
        "    to be used by decoder'''\n",
        "    initializer = self.initializer\n",
        "    # initializing decoder transformation matrix\n",
        "    values = initializer(shape=(decoder_hidden_state.shape[2],encoder_output.shape[2])) # [dec_embed_dim, encoder_lstm_units]\n",
        "    # tranforming decoder input\n",
        "    similarity1 = tf.matmul(decoder_hidden_state,values) # [b,1,dec_embed_dim] X [dec_embed_dim, encoder_lstm_units] = [b,1,encoder_lstm_units]\n",
        "    # finding similarity score\n",
        "    similarity = tf.matmul(similarity1,encoder_output, transpose_b=True) # [b,1,encoder_lstm_units] X [b,encoder_lstm_units,max_len] = [b,1,max_len]\n",
        "    # normalizing scores using softmax\n",
        "    attn_weights = tf.nn.softmax( similarity,axis=-1 ) # [b,1,max_len]\n",
        "    # calculating weighted sum\n",
        "    context_vector = tf.matmul(attn_weights,encoder_output) # [b,1,max_len] X -[b,max_len,encoder_lstm_units] = [b,1,encoder_lstm_units]\n",
        "    context_vector = tf.squeeze(context_vector,axis=1) # [b,encoder_lstm_units]\n",
        "    attn_weights = tf.transpose(attn_weights, perm=[0, 2, 1]) # [b,max_len,1]\n",
        "    return context_vector, attn_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrxpKs1LJ7T1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f846e084-ffb2-426c-d029-0f1b6da60189"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([16, 32]), TensorShape([16, 10, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# checking code\n",
        "\n",
        "input_length=10\n",
        "batch_size=16\n",
        "encoder_lstm_units=32\n",
        "dec_embed_dim=50\n",
        "\n",
        "decoder_hidden_state=tf.random.uniform(shape=[batch_size,1,dec_embed_dim])\n",
        "encoder_output=tf.random.uniform(shape=[batch_size,input_length,encoder_lstm_units])\n",
        "\n",
        "attn=AttentionMechanism()\n",
        "c,wt = attn(decoder_hidden_state,encoder_output)\n",
        "c.shape , wt.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder Encoder Cross Attention:**"
      ],
      "metadata": {
        "id": "ChIW-4Y_sl5D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7BPvFlmoPVC"
      },
      "outputs": [],
      "source": [
        "class DecoderEncoderCrossAttention(tf.keras.Model):\n",
        "  '''class that performs cross attention on decoder input, pass the attention updated input to\n",
        "  lstm and then to final dense layer having units equal to output vocab size. the decoder input is passed\n",
        "  one word at a time over batch'''\n",
        "  def __init__(self,tar_vocab_size, embedding_dim_dec, input_length, dec_units, lstm_dropout, recurrent_dropout, trainable=True):\n",
        "    super().__init__()\n",
        "    self.tar_vocab_size = tar_vocab_size\n",
        "    self.embedding_dim_dec = embedding_dim_dec\n",
        "    self.input_length = input_length\n",
        "    self.dec_units = dec_units\n",
        "    self.lstm_dropout = lstm_dropout\n",
        "    self.recurrent_dropout = recurrent_dropout \n",
        "    self.trainable = True\n",
        "\n",
        "  def get_config(self):\n",
        "      config = super().get_config()\n",
        "      config.update({\n",
        "          'tar_vocab_size': self.tar_vocab_size, 'embedding_dim_dec': self.embedding_dim_dec,\n",
        "          'input_length': self.input_length, 'dec_units': self.dec_units, 'trainable': self.trainable})\n",
        "      return config\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    if self.trainable:\n",
        "      self.embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim_dec, input_length=self.input_length,\n",
        "                        mask_zero=True, name=\"embedding_layer_decoder\", trainable=True)\n",
        "    else:\n",
        "      self.embedding = Embedding(input_dim=self.tar_vocab_size, output_dim=self.embedding_dim_dec, input_length=self.input_length,\n",
        "                        mask_zero=True, name=\"embedding_layer_decoder\", weights=[embedding_matrix], trainable=False)\n",
        "\n",
        "    self.lstm = LSTM(self.dec_units, return_sequences=True, return_state=True,dropout=self.lstm_dropout,recurrent_dropout=self.recurrent_dropout, name=\"Encoder_LSTM\")\n",
        "    self.attention = AttentionMechanism()\n",
        "    self.dense_layer = Dense(self.tar_vocab_size,activation=None)\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output): \n",
        "    '''takes decoder single input over batch, encoder outputs, performs cross attention and returns returns logits'''\n",
        "    # embedding decoder single input\n",
        "    target_embedd = self.embedding(input_to_decoder) # [b,1,embedding_dim_dec]\n",
        "    # getting attention updated embedding vector\n",
        "    context_vector,_ = self.attention(target_embedd,encoder_output) #[b,encoder_lstm_units]\n",
        "    # concataneting embeded input and attention updated input\n",
        "    concat_input = tf.concat([target_embedd, tf.expand_dims(context_vector, 1)], -1)  # [b,1,(embedding_dim_dec+encoder_lstm_units)] \n",
        "    # passing to lstm\n",
        "    self.lstm_output, self.lstm_state_h, self.lstm_state_c = self.lstm(concat_input) # [b,1,dec_lstm_units] , [b,1,dec_lstm_units] , [b,1,dec_lstm_units]\n",
        "    # getting logits\n",
        "    output = self.dense_layer(self.lstm_output)  # [b,1,tar_vocab_size]\n",
        "    output = tf.squeeze(output,axis=1) # [b,tar_vocab_size]\n",
        "    return output, self.lstm_state_h,self.lstm_state_c, context_vector                                                   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88okyUfSPUXa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cafe97e-bf6a-4cc3-e27c-5681f38077a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# checking code\n",
        "\n",
        "tar_vocab_size=150\n",
        "embedding_dim_dec=50\n",
        "input_length=10\n",
        "dec_units=48\n",
        "batch_size=16\n",
        "lstm_dropout = 0.5\n",
        "recurrent_dropout=0.5\n",
        "\n",
        "input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "encoder_output=tf.random.uniform(shape=[batch_size,input_length,32])\n",
        "\n",
        "d = DecoderEncoderCrossAttention(tar_vocab_size,embedding_dim_dec,input_length,dec_units,lstm_dropout,recurrent_dropout)\n",
        "o,_,_,_ = d(input_to_decoder,encoder_output)\n",
        "o.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decoder Layer:**"
      ],
      "metadata": {
        "id": "IphUR5eos1bB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Jduzh3ZP7sm"
      },
      "outputs": [],
      "source": [
        "class DecoderBlock(tf.keras.Model):\n",
        "  '''class which gives logits values for full decoder input length '''\n",
        "  def __init__(self,out_vocab_size, embedding_dim_dec, input_length, dec_units,lstm_dropout,recurrent_dropout):\n",
        "    super().__init__()\n",
        "    self.out_vocab_size = out_vocab_size\n",
        "    self.embedding_dim_dec = embedding_dim_dec\n",
        "    self.input_length = input_length\n",
        "    self.dec_units = dec_units\n",
        "    self.lstm_dropout = lstm_dropout\n",
        "    self.recurrent_dropout = recurrent_dropout\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({\n",
        "        'out_vocab_size': self.out_vocab_size, 'embedding_dim_dec': self.embedding_dim_dec,\n",
        "        'input_length': self.input_length, 'dec_units': self.dec_units})\n",
        "    return config\n",
        "\n",
        "  def build(self,input_shapes):\n",
        "    self.crossattention = DecoderEncoderCrossAttention(self.out_vocab_size, self.embedding_dim_dec, self.input_length,\\\n",
        "                                                        self.dec_units ,self.lstm_dropout,self.recurrent_dropout,False)\n",
        "\n",
        "  def call(self, input_to_decoder,encoder_output):\n",
        "    # creating a empty array of length equal to input length to fill logits value\n",
        "    all_outputs = tf.TensorArray(tf.float32,size=self.input_length)\n",
        "    # iterating over individual input word\n",
        "    for timestep in range(self.input_length):\n",
        "      # getting logits value for current input word\n",
        "      output, decoder_hidden_state,decoder_cell_state,_ = self.crossattention(input_to_decoder[:,timestep:timestep+1], encoder_output)\n",
        "      all_outputs = all_outputs.write(timestep, output) #[max_len,b,tar_vocab_size]\n",
        "    all_outputs = tf.transpose(all_outputs.stack(), [1,0,2]) #[b,max_len,tar_vocab_size]\n",
        "    return all_outputs "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking code\n",
        "\n",
        "tar_vocab_size=150 \n",
        "embedding_dim_dec=50\n",
        "input_length=10\n",
        "dec_units=48\n",
        "enc_units = 32\n",
        "batch_size=16\n",
        "lstm_dropout=0.4\n",
        "recurrent_dropout=0.4\n",
        "\n",
        "input_to_decoder=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "encoder_output=tf.random.uniform(shape=[batch_size,input_length,enc_units])\n",
        "\n",
        "d =  DecoderBlock(tar_vocab_size,embedding_dim_dec,input_length,dec_units,lstm_dropout,recurrent_dropout)\n",
        "d(input_to_decoder,encoder_output).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KclSF4i_l6m-",
        "outputId": "942c1f5b-d899-471e-f772-dac3281ee7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([16, 10, 150])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model:**"
      ],
      "metadata": {
        "id": "ImkfLXpts7CZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqypHJSjy9qD"
      },
      "outputs": [],
      "source": [
        "class TranslationModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, encoder_inputs_length,decoder_inputs_length, vocab_size_ita,vocab_size_eng,\\\n",
        "                embedding_dim_enc,embedding_dim_dec,enc_units,dec_units,lstm_dropout,recurrent_dropout):\n",
        "    super().__init__()\n",
        "    self.encoder_inputs_length = encoder_inputs_length\n",
        "    self.decoder_inputs_length = decoder_inputs_length\n",
        "    self.vocab_size_ita = vocab_size_ita\n",
        "    self.vocab_size_eng = vocab_size_eng\n",
        "    self.embedding_dim_enc = embedding_dim_enc\n",
        "    self.embedding_dim_dec = embedding_dim_dec\n",
        "    self.enc_units = enc_units\n",
        "    self.dec_units = dec_units\n",
        "    self.lstm_dropout = lstm_dropout\n",
        "    self.recurrent_dropout = recurrent_dropout\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config()\n",
        "    config.update({'encoder_inputs_length': self.encoder_inputs_length, 'decoder_inputs_length': self.decoder_inputs_length,\n",
        "        'vocab_size_ita': self.vocab_size_ita, 'vocab_size_eng': self.vocab_size_eng, 'embedding_dim_enc': self.embedding_dim_enc,\n",
        "        'embedding_dim_dec': self.embedding_dim_dec , 'enc_units': self.enc_units, 'dec_units': self.dec_units, 'att_units': self.att_units})\n",
        "    return config\n",
        "\n",
        "  def build(self,input_shapes):\n",
        "      self.encoder = Encoder(self.vocab_size_ita+1, self.embedding_dim_enc, self.encoder_inputs_length,\\\n",
        "                             self.enc_units,self.lstm_dropout,self.recurrent_dropout)\n",
        "      self.decoder = DecoderBlock(self.vocab_size_eng+1, self.embedding_dim_dec, decoder_inputs_length,\\\n",
        "                                  self.lstm_dropout,self.recurrent_dropout)\n",
        "      \n",
        "  def call(self, data):\n",
        "      input,output = data[0], data[1]\n",
        "      #passing input to encoder\n",
        "      encoder_output = self.encoder(input) #[b,max_len,encoder_lstm_units]\n",
        "      #passing output to decoder\n",
        "      decoder_output = self.decoder(output, encoder_output) #[b,max_len,tar_vocab_size] #logits\n",
        "      return decoder_output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loss Function:**"
      ],
      "metadata": {
        "id": "Fidzi9Ams_ng"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6AokS4N84R2"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zero.\"\"\"\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "    return tf.reduce_mean(loss_)\n",
        "\n",
        "def masked_acc(labels, preds):\n",
        "  mask = tf.cast(labels!=0, tf.float32)\n",
        "  preds = tf.argmax(preds, axis=-1)\n",
        "  labels = tf.cast(labels, tf.int64)\n",
        "  match = tf.cast(preds == labels, mask.dtype)\n",
        "  acc = tf.reduce_sum(match*mask)/tf.reduce_sum(mask)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Callbacks:**"
      ],
      "metadata": {
        "id": "xgdBekgItS9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "import os\n",
        "import datetime\n",
        "log_dir = os.path.join('/content/drive/MyDrive/cross_attention/',\"logs\",'model','fits', datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1,write_graph=True)\n",
        "\n",
        "modelsave_wt = tf.keras.callbacks.ModelCheckpoint(\n",
        "                     filepath='/content/drive/MyDrive/cross_attention/model.{epoch:02d}-{masked_acc:.4f}.h5', \n",
        "                     save_freq='epoch', verbose=1, monitor='masked_acc', \n",
        "                     save_weights_only=True, save_best_only=True\n",
        "                 ) "
      ],
      "metadata": {
        "id": "ByVgmrHNjWQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Selected Hyperparameters:**"
      ],
      "metadata": {
        "id": "jarUOOF8tveQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vocab_size_ita=27260\n",
        "#vocab_size_eng=13356"
      ],
      "metadata": {
        "id": "9SKneqQJt6a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ60N_XTB-80"
      },
      "outputs": [],
      "source": [
        "# after trying different values, following were selected\n",
        "\n",
        "encoder_inputs_length = 20\n",
        "decoder_inputs_length = 20\n",
        "vocab_size_ita = vocab_size_ita\n",
        "vocab_size_eng = vocab_size_eng\n",
        "embedding_dim_enc = 100\n",
        "embedding_dim_dec = 100\n",
        "enc_units = 128\n",
        "dec_units = 128\n",
        "lstm_dropout = 0.2\n",
        "recurrent_dropout = 0.2\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Loader:**"
      ],
      "metadata": {
        "id": "xhaBrnzxuFbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=1024\n",
        "\n",
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
        "val_dataset  = Dataset(val, tknizer_ita, tknizer_eng, 20)\n",
        "test_dataset  = Dataset(test, tknizer_ita, tknizer_eng, 20)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "val_dataloader = Dataloder(val_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n",
        "\n",
        "train_steps=train.shape[0]//batch_size\n",
        "valid_steps=val.shape[0]//batch_size"
      ],
      "metadata": {
        "id": "l5zitOnljwSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training:**"
      ],
      "metadata": {
        "id": "o-9roTDYuJnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model  = TranslationModel(encoder_inputs_length,decoder_inputs_length, vocab_size_ita,vocab_size_eng,embedding_dim_enc,\\\n",
        "                          embedding_dim_dec,enc_units,dec_units, lstm_dropout, recurrent_dropout)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_function, metrics=[masked_acc])"
      ],
      "metadata": {
        "id": "bY44-saA-FNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=10, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cmHvCDqFgLN",
        "outputId": "797d1c33-7502-492b-fc92-51b2c6d5da45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer Encoder_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer Encoder_LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "/usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.9879 - masked_acc: 0.1504\n",
            "Epoch 1: masked_acc improved from 0.14619 to 0.15041, saving model to /content/drive/MyDrive/cross_attention/model.01-0.1504.h5\n",
            "296/296 [==============================] - 292s 748ms/step - loss: 1.9879 - masked_acc: 0.1504 - val_loss: 1.6638 - val_masked_acc: 0.1911\n",
            "Epoch 2/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.5426 - masked_acc: 0.2328\n",
            "Epoch 2: masked_acc improved from 0.15041 to 0.23276, saving model to /content/drive/MyDrive/cross_attention/model.02-0.2328.h5\n",
            "296/296 [==============================] - 197s 665ms/step - loss: 1.5426 - masked_acc: 0.2328 - val_loss: 1.4218 - val_masked_acc: 0.2831\n",
            "Epoch 3/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.3747 - masked_acc: 0.3093\n",
            "Epoch 3: masked_acc improved from 0.23276 to 0.30925, saving model to /content/drive/MyDrive/cross_attention/model.03-0.3093.h5\n",
            "296/296 [==============================] - 195s 659ms/step - loss: 1.3747 - masked_acc: 0.3093 - val_loss: 1.3202 - val_masked_acc: 0.3340\n",
            "Epoch 4/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.2947 - masked_acc: 0.3424\n",
            "Epoch 4: masked_acc improved from 0.30925 to 0.34244, saving model to /content/drive/MyDrive/cross_attention/model.04-0.3424.h5\n",
            "296/296 [==============================] - 193s 652ms/step - loss: 1.2947 - masked_acc: 0.3424 - val_loss: 1.2543 - val_masked_acc: 0.3572\n",
            "Epoch 5/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.2362 - masked_acc: 0.3634\n",
            "Epoch 5: masked_acc improved from 0.34244 to 0.36345, saving model to /content/drive/MyDrive/cross_attention/model.05-0.3634.h5\n",
            "296/296 [==============================] - 196s 661ms/step - loss: 1.2362 - masked_acc: 0.3634 - val_loss: 1.2015 - val_masked_acc: 0.3737\n",
            "Epoch 6/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.1868 - masked_acc: 0.3822\n",
            "Epoch 6: masked_acc improved from 0.36345 to 0.38222, saving model to /content/drive/MyDrive/cross_attention/model.06-0.3822.h5\n",
            "296/296 [==============================] - 194s 656ms/step - loss: 1.1868 - masked_acc: 0.3822 - val_loss: 1.1559 - val_masked_acc: 0.3972\n",
            "Epoch 7/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.1442 - masked_acc: 0.4000\n",
            "Epoch 7: masked_acc improved from 0.38222 to 0.40001, saving model to /content/drive/MyDrive/cross_attention/model.07-0.4000.h5\n",
            "296/296 [==============================] - 191s 645ms/step - loss: 1.1442 - masked_acc: 0.4000 - val_loss: 1.1166 - val_masked_acc: 0.4130\n",
            "Epoch 8/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.1061 - masked_acc: 0.4158\n",
            "Epoch 8: masked_acc improved from 0.40001 to 0.41582, saving model to /content/drive/MyDrive/cross_attention/model.08-0.4158.h5\n",
            "296/296 [==============================] - 194s 654ms/step - loss: 1.1061 - masked_acc: 0.4158 - val_loss: 1.0793 - val_masked_acc: 0.4311\n",
            "Epoch 9/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.0695 - masked_acc: 0.4324\n",
            "Epoch 9: masked_acc improved from 0.41582 to 0.43236, saving model to /content/drive/MyDrive/cross_attention/model.09-0.4324.h5\n",
            "296/296 [==============================] - 195s 658ms/step - loss: 1.0695 - masked_acc: 0.4324 - val_loss: 1.0414 - val_masked_acc: 0.4501\n",
            "Epoch 10/10\n",
            "296/296 [==============================] - ETA: 0s - loss: 1.0310 - masked_acc: 0.4501\n",
            "Epoch 10: masked_acc improved from 0.43236 to 0.45006, saving model to /content/drive/MyDrive/cross_attention/model.10-0.4501.h5\n",
            "296/296 [==============================] - 200s 677ms/step - loss: 1.0310 - masked_acc: 0.4501 - val_loss: 1.0026 - val_masked_acc: 0.4677\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0db44b4fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=20, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback],initial_epoch=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk98ChmsOvsf",
        "outputId": "9fe2f224-b9a6-4933-b659-d9d92b4f30a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.9896 - masked_acc: 0.4684\n",
            "Epoch 11: masked_acc improved from 0.45006 to 0.46839, saving model to /content/drive/MyDrive/cross_attention/model.11-0.4684.h5\n",
            "296/296 [==============================] - 197s 656ms/step - loss: 0.9896 - masked_acc: 0.4684 - val_loss: 0.9552 - val_masked_acc: 0.4896\n",
            "Epoch 12/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.9457 - masked_acc: 0.4873\n",
            "Epoch 12: masked_acc improved from 0.46839 to 0.48731, saving model to /content/drive/MyDrive/cross_attention/model.12-0.4873.h5\n",
            "296/296 [==============================] - 193s 651ms/step - loss: 0.9457 - masked_acc: 0.4873 - val_loss: 0.9081 - val_masked_acc: 0.5109\n",
            "Epoch 13/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.8992 - masked_acc: 0.5079\n",
            "Epoch 13: masked_acc improved from 0.48731 to 0.50789, saving model to /content/drive/MyDrive/cross_attention/model.13-0.5079.h5\n",
            "296/296 [==============================] - 195s 656ms/step - loss: 0.8992 - masked_acc: 0.5079 - val_loss: 0.8567 - val_masked_acc: 0.5352\n",
            "Epoch 14/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.8475 - masked_acc: 0.5315\n",
            "Epoch 14: masked_acc improved from 0.50789 to 0.53154, saving model to /content/drive/MyDrive/cross_attention/model.14-0.5315.h5\n",
            "296/296 [==============================] - 195s 659ms/step - loss: 0.8475 - masked_acc: 0.5315 - val_loss: 0.7992 - val_masked_acc: 0.5628\n",
            "Epoch 15/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.7918 - masked_acc: 0.5580\n",
            "Epoch 15: masked_acc improved from 0.53154 to 0.55796, saving model to /content/drive/MyDrive/cross_attention/model.15-0.5580.h5\n",
            "296/296 [==============================] - 194s 655ms/step - loss: 0.7918 - masked_acc: 0.5580 - val_loss: 0.7398 - val_masked_acc: 0.5911\n",
            "Epoch 16/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.7354 - masked_acc: 0.5856\n",
            "Epoch 16: masked_acc improved from 0.55796 to 0.58560, saving model to /content/drive/MyDrive/cross_attention/model.16-0.5856.h5\n",
            "296/296 [==============================] - 196s 661ms/step - loss: 0.7354 - masked_acc: 0.5856 - val_loss: 0.6804 - val_masked_acc: 0.6243\n",
            "Epoch 17/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.6817 - masked_acc: 0.6125\n",
            "Epoch 17: masked_acc improved from 0.58560 to 0.61246, saving model to /content/drive/MyDrive/cross_attention/model.17-0.6125.h5\n",
            "296/296 [==============================] - 194s 655ms/step - loss: 0.6817 - masked_acc: 0.6125 - val_loss: 0.6288 - val_masked_acc: 0.6501\n",
            "Epoch 18/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.6336 - masked_acc: 0.6362\n",
            "Epoch 18: masked_acc improved from 0.61246 to 0.63623, saving model to /content/drive/MyDrive/cross_attention/model.18-0.6362.h5\n",
            "296/296 [==============================] - 194s 657ms/step - loss: 0.6336 - masked_acc: 0.6362 - val_loss: 0.5833 - val_masked_acc: 0.6736\n",
            "Epoch 19/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.5894 - masked_acc: 0.6576\n",
            "Epoch 19: masked_acc improved from 0.63623 to 0.65760, saving model to /content/drive/MyDrive/cross_attention/model.19-0.6576.h5\n",
            "296/296 [==============================] - 195s 658ms/step - loss: 0.5894 - masked_acc: 0.6576 - val_loss: 0.5431 - val_masked_acc: 0.6940\n",
            "Epoch 20/20\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.5522 - masked_acc: 0.6756\n",
            "Epoch 20: masked_acc improved from 0.65760 to 0.67557, saving model to /content/drive/MyDrive/cross_attention/model.20-0.6756.h5\n",
            "296/296 [==============================] - 197s 664ms/step - loss: 0.5522 - masked_acc: 0.6756 - val_loss: 0.5135 - val_masked_acc: 0.7092\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c913a68b0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback],initial_epoch=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVw2Ul52YT_o",
        "outputId": "113f2278-d869-4a18-d1a0-be0f95b5ba64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.5190 - masked_acc: 0.6916\n",
            "Epoch 21: masked_acc improved from 0.67557 to 0.69156, saving model to /content/drive/MyDrive/cross_attention/model.21-0.6916.h5\n",
            "296/296 [==============================] - 198s 665ms/step - loss: 0.5190 - masked_acc: 0.6916 - val_loss: 0.4794 - val_masked_acc: 0.7257\n",
            "Epoch 22/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.4882 - masked_acc: 0.7065\n",
            "Epoch 22: masked_acc improved from 0.69156 to 0.70654, saving model to /content/drive/MyDrive/cross_attention/model.22-0.7065.h5\n",
            "296/296 [==============================] - 197s 666ms/step - loss: 0.4882 - masked_acc: 0.7065 - val_loss: 0.4541 - val_masked_acc: 0.7388\n",
            "Epoch 23/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.4623 - masked_acc: 0.7191\n",
            "Epoch 23: masked_acc improved from 0.70654 to 0.71911, saving model to /content/drive/MyDrive/cross_attention/model.23-0.7191.h5\n",
            "296/296 [==============================] - 194s 656ms/step - loss: 0.4623 - masked_acc: 0.7191 - val_loss: 0.4318 - val_masked_acc: 0.7501\n",
            "Epoch 24/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.4396 - masked_acc: 0.7302\n",
            "Epoch 24: masked_acc improved from 0.71911 to 0.73017, saving model to /content/drive/MyDrive/cross_attention/model.24-0.7302.h5\n",
            "296/296 [==============================] - 192s 648ms/step - loss: 0.4396 - masked_acc: 0.7302 - val_loss: 0.4130 - val_masked_acc: 0.7592\n",
            "Epoch 25/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.4194 - masked_acc: 0.7398\n",
            "Epoch 25: masked_acc improved from 0.73017 to 0.73983, saving model to /content/drive/MyDrive/cross_attention/model.25-0.7398.h5\n",
            "296/296 [==============================] - 192s 647ms/step - loss: 0.4194 - masked_acc: 0.7398 - val_loss: 0.3975 - val_masked_acc: 0.7674\n",
            "Epoch 26/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.4018 - masked_acc: 0.7485\n",
            "Epoch 26: masked_acc improved from 0.73983 to 0.74851, saving model to /content/drive/MyDrive/cross_attention/model.26-0.7485.h5\n",
            "296/296 [==============================] - 191s 645ms/step - loss: 0.4018 - masked_acc: 0.7485 - val_loss: 0.3822 - val_masked_acc: 0.7748\n",
            "Epoch 27/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3851 - masked_acc: 0.7563\n",
            "Epoch 27: masked_acc improved from 0.74851 to 0.75629, saving model to /content/drive/MyDrive/cross_attention/model.27-0.7563.h5\n",
            "296/296 [==============================] - 191s 645ms/step - loss: 0.3851 - masked_acc: 0.7563 - val_loss: 0.3703 - val_masked_acc: 0.7808\n",
            "Epoch 28/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3707 - masked_acc: 0.7634\n",
            "Epoch 28: masked_acc improved from 0.75629 to 0.76343, saving model to /content/drive/MyDrive/cross_attention/model.28-0.7634.h5\n",
            "296/296 [==============================] - 190s 642ms/step - loss: 0.3707 - masked_acc: 0.7634 - val_loss: 0.3592 - val_masked_acc: 0.7858\n",
            "Epoch 29/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3582 - masked_acc: 0.7693\n",
            "Epoch 29: masked_acc improved from 0.76343 to 0.76926, saving model to /content/drive/MyDrive/cross_attention/model.29-0.7693.h5\n",
            "296/296 [==============================] - 192s 649ms/step - loss: 0.3582 - masked_acc: 0.7693 - val_loss: 0.3495 - val_masked_acc: 0.7911\n",
            "Epoch 30/30\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3465 - masked_acc: 0.7753\n",
            "Epoch 30: masked_acc improved from 0.76926 to 0.77534, saving model to /content/drive/MyDrive/cross_attention/model.30-0.7753.h5\n",
            "296/296 [==============================] - 190s 640ms/step - loss: 0.3465 - masked_acc: 0.7753 - val_loss: 0.3406 - val_masked_acc: 0.7958\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f6291c790>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=40, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback],initial_epoch=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CiU_eqtZg6ux",
        "outputId": "eff6ff40-0f3c-49ac-dc6d-b76af8b784b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3364 - masked_acc: 0.7803\n",
            "Epoch 31: masked_acc improved from 0.77534 to 0.78026, saving model to /content/drive/MyDrive/cross_attention/model.31-0.7803.h5\n",
            "296/296 [==============================] - 198s 662ms/step - loss: 0.3364 - masked_acc: 0.7803 - val_loss: 0.3332 - val_masked_acc: 0.7998\n",
            "Epoch 32/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3272 - masked_acc: 0.7846\n",
            "Epoch 32: masked_acc improved from 0.78026 to 0.78462, saving model to /content/drive/MyDrive/cross_attention/model.32-0.7846.h5\n",
            "296/296 [==============================] - 196s 663ms/step - loss: 0.3272 - masked_acc: 0.7846 - val_loss: 0.3257 - val_masked_acc: 0.8036\n",
            "Epoch 33/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3184 - masked_acc: 0.7889\n",
            "Epoch 33: masked_acc improved from 0.78462 to 0.78893, saving model to /content/drive/MyDrive/cross_attention/model.33-0.7889.h5\n",
            "296/296 [==============================] - 194s 656ms/step - loss: 0.3184 - masked_acc: 0.7889 - val_loss: 0.3189 - val_masked_acc: 0.8065\n",
            "Epoch 34/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3124 - masked_acc: 0.7917\n",
            "Epoch 34: masked_acc improved from 0.78893 to 0.79167, saving model to /content/drive/MyDrive/cross_attention/model.34-0.7917.h5\n",
            "296/296 [==============================] - 193s 653ms/step - loss: 0.3124 - masked_acc: 0.7917 - val_loss: 0.3132 - val_masked_acc: 0.8094\n",
            "Epoch 35/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.3029 - masked_acc: 0.7966\n",
            "Epoch 35: masked_acc improved from 0.79167 to 0.79662, saving model to /content/drive/MyDrive/cross_attention/model.35-0.7966.h5\n",
            "296/296 [==============================] - 195s 658ms/step - loss: 0.3029 - masked_acc: 0.7966 - val_loss: 0.3076 - val_masked_acc: 0.8127\n",
            "Epoch 36/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2963 - masked_acc: 0.7999\n",
            "Epoch 36: masked_acc improved from 0.79662 to 0.79986, saving model to /content/drive/MyDrive/cross_attention/model.36-0.7999.h5\n",
            "296/296 [==============================] - 196s 662ms/step - loss: 0.2963 - masked_acc: 0.7999 - val_loss: 0.3029 - val_masked_acc: 0.8154\n",
            "Epoch 37/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2900 - masked_acc: 0.8032\n",
            "Epoch 37: masked_acc improved from 0.79986 to 0.80323, saving model to /content/drive/MyDrive/cross_attention/model.37-0.8032.h5\n",
            "296/296 [==============================] - 196s 663ms/step - loss: 0.2900 - masked_acc: 0.8032 - val_loss: 0.2976 - val_masked_acc: 0.8180\n",
            "Epoch 38/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2842 - masked_acc: 0.8061\n",
            "Epoch 38: masked_acc improved from 0.80323 to 0.80605, saving model to /content/drive/MyDrive/cross_attention/model.38-0.8061.h5\n",
            "296/296 [==============================] - 195s 658ms/step - loss: 0.2842 - masked_acc: 0.8061 - val_loss: 0.2938 - val_masked_acc: 0.8202\n",
            "Epoch 39/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2788 - masked_acc: 0.8084\n",
            "Epoch 39: masked_acc improved from 0.80605 to 0.80838, saving model to /content/drive/MyDrive/cross_attention/model.39-0.8084.h5\n",
            "296/296 [==============================] - 206s 696ms/step - loss: 0.2788 - masked_acc: 0.8084 - val_loss: 0.2898 - val_masked_acc: 0.8221\n",
            "Epoch 40/40\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2739 - masked_acc: 0.8111\n",
            "Epoch 40: masked_acc improved from 0.80838 to 0.81110, saving model to /content/drive/MyDrive/cross_attention/model.40-0.8111.h5\n",
            "296/296 [==============================] - 196s 661ms/step - loss: 0.2739 - masked_acc: 0.8111 - val_loss: 0.2861 - val_masked_acc: 0.8243\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c922c7ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=50, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback],initial_epoch=40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcbY4FcLnUpK",
        "outputId": "8b955606-27d1-4484-813d-235cf8a2736e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2689 - masked_acc: 0.8138\n",
            "Epoch 41: masked_acc improved from 0.81110 to 0.81379, saving model to /content/drive/MyDrive/cross_attention/model.41-0.8138.h5\n",
            "296/296 [==============================] - 199s 667ms/step - loss: 0.2689 - masked_acc: 0.8138 - val_loss: 0.2834 - val_masked_acc: 0.8253\n",
            "Epoch 42/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2649 - masked_acc: 0.8155\n",
            "Epoch 42: masked_acc improved from 0.81379 to 0.81554, saving model to /content/drive/MyDrive/cross_attention/model.42-0.8155.h5\n",
            "296/296 [==============================] - 195s 658ms/step - loss: 0.2649 - masked_acc: 0.8155 - val_loss: 0.2801 - val_masked_acc: 0.8273\n",
            "Epoch 43/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2602 - masked_acc: 0.8180\n",
            "Epoch 43: masked_acc improved from 0.81554 to 0.81800, saving model to /content/drive/MyDrive/cross_attention/model.43-0.8180.h5\n",
            "296/296 [==============================] - 192s 650ms/step - loss: 0.2602 - masked_acc: 0.8180 - val_loss: 0.2771 - val_masked_acc: 0.8290\n",
            "Epoch 44/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2560 - masked_acc: 0.8202\n",
            "Epoch 44: masked_acc improved from 0.81800 to 0.82016, saving model to /content/drive/MyDrive/cross_attention/model.44-0.8202.h5\n",
            "296/296 [==============================] - 191s 647ms/step - loss: 0.2560 - masked_acc: 0.8202 - val_loss: 0.2738 - val_masked_acc: 0.8310\n",
            "Epoch 45/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2520 - masked_acc: 0.8224\n",
            "Epoch 45: masked_acc improved from 0.82016 to 0.82238, saving model to /content/drive/MyDrive/cross_attention/model.45-0.8224.h5\n",
            "296/296 [==============================] - 193s 652ms/step - loss: 0.2520 - masked_acc: 0.8224 - val_loss: 0.2719 - val_masked_acc: 0.8325\n",
            "Epoch 46/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2484 - masked_acc: 0.8242\n",
            "Epoch 46: masked_acc improved from 0.82238 to 0.82418, saving model to /content/drive/MyDrive/cross_attention/model.46-0.8242.h5\n",
            "296/296 [==============================] - 196s 661ms/step - loss: 0.2484 - masked_acc: 0.8242 - val_loss: 0.2689 - val_masked_acc: 0.8340\n",
            "Epoch 47/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2453 - masked_acc: 0.8256\n",
            "Epoch 47: masked_acc improved from 0.82418 to 0.82559, saving model to /content/drive/MyDrive/cross_attention/model.47-0.8256.h5\n",
            "296/296 [==============================] - 193s 649ms/step - loss: 0.2453 - masked_acc: 0.8256 - val_loss: 0.2674 - val_masked_acc: 0.8346\n",
            "Epoch 48/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2418 - masked_acc: 0.8276\n",
            "Epoch 48: masked_acc improved from 0.82559 to 0.82761, saving model to /content/drive/MyDrive/cross_attention/model.48-0.8276.h5\n",
            "296/296 [==============================] - 194s 654ms/step - loss: 0.2418 - masked_acc: 0.8276 - val_loss: 0.2646 - val_masked_acc: 0.8368\n",
            "Epoch 49/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2389 - masked_acc: 0.8293\n",
            "Epoch 49: masked_acc improved from 0.82761 to 0.82928, saving model to /content/drive/MyDrive/cross_attention/model.49-0.8293.h5\n",
            "296/296 [==============================] - 194s 655ms/step - loss: 0.2389 - masked_acc: 0.8293 - val_loss: 0.2627 - val_masked_acc: 0.8381\n",
            "Epoch 50/50\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2362 - masked_acc: 0.8307\n",
            "Epoch 50: masked_acc improved from 0.82928 to 0.83072, saving model to /content/drive/MyDrive/cross_attention/model.50-0.8307.h5\n",
            "296/296 [==============================] - 192s 650ms/step - loss: 0.2362 - masked_acc: 0.8307 - val_loss: 0.2601 - val_masked_acc: 0.8389\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0caa8cf100>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=60, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback],initial_epoch=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIS5VLddxqau",
        "outputId": "16ca3c4f-f1de-4a03-bee8-86a4f1c3a724"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2331 - masked_acc: 0.8322\n",
            "Epoch 51: masked_acc improved from 0.83072 to 0.83216, saving model to /content/drive/MyDrive/cross_attention/model.51-0.8322.h5\n",
            "296/296 [==============================] - 201s 670ms/step - loss: 0.2331 - masked_acc: 0.8322 - val_loss: 0.2590 - val_masked_acc: 0.8400\n",
            "Epoch 52/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2304 - masked_acc: 0.8339\n",
            "Epoch 52: masked_acc improved from 0.83216 to 0.83391, saving model to /content/drive/MyDrive/cross_attention/model.52-0.8339.h5\n",
            "296/296 [==============================] - 194s 657ms/step - loss: 0.2304 - masked_acc: 0.8339 - val_loss: 0.2566 - val_masked_acc: 0.8417\n",
            "Epoch 53/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2278 - masked_acc: 0.8351\n",
            "Epoch 53: masked_acc improved from 0.83391 to 0.83507, saving model to /content/drive/MyDrive/cross_attention/model.53-0.8351.h5\n",
            "296/296 [==============================] - 197s 666ms/step - loss: 0.2278 - masked_acc: 0.8351 - val_loss: 0.2554 - val_masked_acc: 0.8423\n",
            "Epoch 54/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2252 - masked_acc: 0.8365\n",
            "Epoch 54: masked_acc improved from 0.83507 to 0.83648, saving model to /content/drive/MyDrive/cross_attention/model.54-0.8365.h5\n",
            "296/296 [==============================] - 195s 658ms/step - loss: 0.2252 - masked_acc: 0.8365 - val_loss: 0.2537 - val_masked_acc: 0.8434\n",
            "Epoch 55/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2229 - masked_acc: 0.8377\n",
            "Epoch 55: masked_acc improved from 0.83648 to 0.83771, saving model to /content/drive/MyDrive/cross_attention/model.55-0.8377.h5\n",
            "296/296 [==============================] - 194s 654ms/step - loss: 0.2229 - masked_acc: 0.8377 - val_loss: 0.2529 - val_masked_acc: 0.8442\n",
            "Epoch 56/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2206 - masked_acc: 0.8390\n",
            "Epoch 56: masked_acc improved from 0.83771 to 0.83903, saving model to /content/drive/MyDrive/cross_attention/model.56-0.8390.h5\n",
            "296/296 [==============================] - 191s 646ms/step - loss: 0.2206 - masked_acc: 0.8390 - val_loss: 0.2505 - val_masked_acc: 0.8454\n",
            "Epoch 57/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2183 - masked_acc: 0.8400\n",
            "Epoch 57: masked_acc improved from 0.83903 to 0.83997, saving model to /content/drive/MyDrive/cross_attention/model.57-0.8400.h5\n",
            "296/296 [==============================] - 193s 651ms/step - loss: 0.2183 - masked_acc: 0.8400 - val_loss: 0.2500 - val_masked_acc: 0.8459\n",
            "Epoch 58/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2167 - masked_acc: 0.8413\n",
            "Epoch 58: masked_acc improved from 0.83997 to 0.84133, saving model to /content/drive/MyDrive/cross_attention/model.58-0.8413.h5\n",
            "296/296 [==============================] - 193s 650ms/step - loss: 0.2167 - masked_acc: 0.8413 - val_loss: 0.2482 - val_masked_acc: 0.8472\n",
            "Epoch 59/60\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2143 - masked_acc: 0.8424\n",
            "Epoch 59: masked_acc improved from 0.84133 to 0.84239, saving model to /content/drive/MyDrive/cross_attention/model.59-0.8424.h5\n",
            "296/296 [==============================] - 194s 654ms/step - loss: 0.2143 - masked_acc: 0.8424 - val_loss: 0.2470 - val_masked_acc: 0.8478\n",
            "Epoch 60/60\n",
            " 76/296 [======>.......................] - ETA: 2:16 - loss: 0.2113 - masked_acc: 0.8441"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=65, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback],initial_epoch=59)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1ZdRLy4fi4N",
        "outputId": "70d22014-98ac-46db-fe44-0738d8ac450e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/65\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2113 - masked_acc: 0.8438\n",
            "Epoch 60: masked_acc improved from 0.84217 to 0.84383, saving model to /content/drive/MyDrive/cross_attention/model.60-0.8438.h5\n",
            "296/296 [==============================] - 190s 636ms/step - loss: 0.2113 - masked_acc: 0.8438 - val_loss: 0.2349 - val_masked_acc: 0.8526\n",
            "Epoch 61/65\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2085 - masked_acc: 0.8453\n",
            "Epoch 61: masked_acc improved from 0.84383 to 0.84530, saving model to /content/drive/MyDrive/cross_attention/model.61-0.8453.h5\n",
            "296/296 [==============================] - 186s 628ms/step - loss: 0.2085 - masked_acc: 0.8453 - val_loss: 0.2329 - val_masked_acc: 0.8539\n",
            "Epoch 62/65\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2060 - masked_acc: 0.8466\n",
            "Epoch 62: masked_acc improved from 0.84530 to 0.84659, saving model to /content/drive/MyDrive/cross_attention/model.62-0.8466.h5\n",
            "296/296 [==============================] - 187s 633ms/step - loss: 0.2060 - masked_acc: 0.8466 - val_loss: 0.2320 - val_masked_acc: 0.8542\n",
            "Epoch 63/65\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2040 - masked_acc: 0.8477\n",
            "Epoch 63: masked_acc improved from 0.84659 to 0.84775, saving model to /content/drive/MyDrive/cross_attention/model.63-0.8477.h5\n",
            "296/296 [==============================] - 187s 633ms/step - loss: 0.2040 - masked_acc: 0.8477 - val_loss: 0.2302 - val_masked_acc: 0.8553\n",
            "Epoch 64/65\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.2016 - masked_acc: 0.8488\n",
            "Epoch 64: masked_acc improved from 0.84775 to 0.84884, saving model to /content/drive/MyDrive/cross_attention/model.64-0.8488.h5\n",
            "296/296 [==============================] - 188s 636ms/step - loss: 0.2016 - masked_acc: 0.8488 - val_loss: 0.2302 - val_masked_acc: 0.8557\n",
            "Epoch 65/65\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.1996 - masked_acc: 0.8502\n",
            "Epoch 65: masked_acc improved from 0.84884 to 0.85021, saving model to /content/drive/MyDrive/cross_attention/model.65-0.8502.h5\n",
            "296/296 [==============================] - 187s 632ms/step - loss: 0.1996 - masked_acc: 0.8502 - val_loss: 0.2278 - val_masked_acc: 0.8569\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e4eccbb20>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataloader, steps_per_epoch=train_steps, epochs=70, validation_data=val_dataloader, validation_steps=valid_steps,\\\n",
        "          callbacks=[modelsave_wt,tensorboard_callback],initial_epoch=65)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn5ON3p3nLtd",
        "outputId": "47592a7b-de78-45de-b169-2f74a16cacb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/70\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.1974 - masked_acc: 0.8510\n",
            "Epoch 66: masked_acc improved from 0.85021 to 0.85099, saving model to /content/drive/MyDrive/cross_attention/model.66-0.8510.h5\n",
            "296/296 [==============================] - 192s 640ms/step - loss: 0.1974 - masked_acc: 0.8510 - val_loss: 0.2268 - val_masked_acc: 0.8570\n",
            "Epoch 67/70\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.1952 - masked_acc: 0.8524\n",
            "Epoch 67: masked_acc improved from 0.85099 to 0.85240, saving model to /content/drive/MyDrive/cross_attention/model.67-0.8524.h5\n",
            "296/296 [==============================] - 188s 635ms/step - loss: 0.1952 - masked_acc: 0.8524 - val_loss: 0.2265 - val_masked_acc: 0.8577\n",
            "Epoch 68/70\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.1935 - masked_acc: 0.8533\n",
            "Epoch 68: masked_acc improved from 0.85240 to 0.85333, saving model to /content/drive/MyDrive/cross_attention/model.68-0.8533.h5\n",
            "296/296 [==============================] - 189s 640ms/step - loss: 0.1935 - masked_acc: 0.8533 - val_loss: 0.2249 - val_masked_acc: 0.8589\n",
            "Epoch 69/70\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.1915 - masked_acc: 0.8547\n",
            "Epoch 69: masked_acc improved from 0.85333 to 0.85469, saving model to /content/drive/MyDrive/cross_attention/model.69-0.8547.h5\n",
            "296/296 [==============================] - 190s 641ms/step - loss: 0.1915 - masked_acc: 0.8547 - val_loss: 0.2240 - val_masked_acc: 0.8597\n",
            "Epoch 70/70\n",
            "296/296 [==============================] - ETA: 0s - loss: 0.1899 - masked_acc: 0.8552\n",
            "Epoch 70: masked_acc improved from 0.85469 to 0.85520, saving model to /content/drive/MyDrive/cross_attention/model.70-0.8552.h5\n",
            "296/296 [==============================] - 191s 644ms/step - loss: 0.1899 - masked_acc: 0.8552 - val_loss: 0.2234 - val_masked_acc: 0.8599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e4ece4100>"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction:**"
      ],
      "metadata": {
        "id": "K1vJhIpUug9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_sentence):\n",
        "  '''takes italian input sentence and outputs translated english sentence'''\n",
        "\n",
        "  encoder_seq = tknizer_ita.texts_to_sequences([input_sentence]) # tokenizing\n",
        "  encoder_seq = pad_sequences(encoder_seq, maxlen=20, dtype='int32', padding='post') #padding to len 20\n",
        "  encoder_output, encoder_h, encoder_c = model.encoder(encoder_seq) # encoding\n",
        "\n",
        "  decoder_input = tknizer_eng.texts_to_sequences(['<start>']) # feeding <start> token as 1st decoder input\n",
        "  decoder_state_h = encoder_h\n",
        "  decoder_state_c = encoder_c\n",
        "  prediction=[]\n",
        "  att_wt = []\n",
        "  for i in range(20): # iterating over full max_length\n",
        "    if i>0 and prediction[-1]==['<end>']: # end translation when <end> token predicted\n",
        "      break\n",
        "    else:\n",
        "      input=tf.expand_dims(decoder_input[0][-1],0)  \n",
        "      if i==0:\n",
        "       input=tf.expand_dims(input,0)\n",
        "      decoder_output, state_h,state_c,attention_weights, context_vector= model.layers[1].cross_attention(input, encoder_output,decoder_state_h,decoder_state_c)\n",
        "      att_wt.append(attention_weights)\n",
        "      index = tf.argmax(decoder_output,axis=-1).numpy()\n",
        "      prediction.append(tknizer_eng.sequences_to_texts([index]))\n",
        "      decoder_input[0].append(index)\n",
        "      decoder_state_h = state_h\n",
        "      decoder_state_c = state_c\n",
        "    \n",
        "  predicted_sent= prediction[0][0]\n",
        "  for word in prediction:\n",
        "    predicted_sent = predicted_sent + ' ' + word[0]\n",
        "  return predicted_sent,att_wt"
      ],
      "metadata": {
        "id": "TWgja-m6i3IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting on random unseen 5 italian sentences\n",
        "\n",
        "for doc in test.sample(5).values:\n",
        "  sent=doc[0]\n",
        "  eng_sent = doc[-1]\n",
        "  print('italian: ',sent)\n",
        "  print('English True: ',eng_sent)\n",
        "  trans,_ = predict(sent)\n",
        "  print('Model Translation: ',trans,'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5a7e1c-b708-4990-d82f-66bd41cef5c9",
        "id": "zVvkF0RBi3IV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "italian:  vedo cosavete fatto lì\n",
            "English True:  i see what you did there <end>\n",
            "Model Translation:  i i see what you have done there <end> \n",
            "\n",
            "italian:  tom non è un fisico\n",
            "English True:  tom is not a physician <end>\n",
            "Model Translation:  tom tom is not a physician <end> \n",
            "\n",
            "italian:  cè un costo di consegna\n",
            "English True:  is there a delivery charge <end>\n",
            "Model Translation:  there there is a charge of the delivery <end> \n",
            "\n",
            "italian:  è un tizio strano\n",
            "English True:  he is a strange guy <end>\n",
            "Model Translation:  it it is a strange guy <end> \n",
            "\n",
            "italian:  tutti qua sanno che non mangiamo la carne di maiale\n",
            "English True:  everyone here knows that we do not eat pork <end>\n",
            "Model Translation:  everyone everyone here knows we do not eat pork <end> \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bleu_score on Test Dataset:**"
      ],
      "metadata": {
        "id": "gRVWaNIaxW1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu"
      ],
      "metadata": {
        "id": "xpJs8vK9i3IX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bleu_score(input,weights):\n",
        "  bleu_score=[]\n",
        "  for doc in input:\n",
        "    input_sentence = doc[0]\n",
        "    eng_sent = doc[-1]\n",
        "    predicted_sent,_ = predict(input_sentence)\n",
        "    bleu_score.append(bleu.sentence_bleu(eng_sent, predicted_sent,weights=weights))\n",
        "  return np.mean(bleu_score)"
      ],
      "metadata": {
        "id": "byxKkWbFi3KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bleu score by only matching uni-grams\n",
        "\n",
        "bleu_score_test = bleu_score( input = test.values, weights = (1,0,0,0) )\n",
        "print('average test data bleu score: ',bleu_score_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "524451ae-fb0b-4bf9-c7cb-a5e3afa88607",
        "id": "TAYTqLwYi3KY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average test data bleu score:  0.4451662890214658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# bleu score by matching 1 to 4-grams\n",
        "\n",
        "bleu_score_test = bleu_score( input = test.values, weights = (0.25,0.25,0.25,0.25) )\n",
        "print('average test data cumulative 4-gram bleu score: ',bleu_score_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCiIpbHRtbdn",
        "outputId": "f2fd6ff8-129c-4b0b-c18e-e4d2070513a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average test data cumulative 4-gram bleu score:  1.479362713798278e-231\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}